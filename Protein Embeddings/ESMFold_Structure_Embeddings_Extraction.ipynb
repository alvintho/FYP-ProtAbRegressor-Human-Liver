{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHsXhpeoB7pt",
        "outputId": "0ab2963f-c715-433f-b163-5447a907c5af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting py3Dmol\n",
            "  Downloading py3Dmol-2.4.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py3Dmol-2.4.2-py2.py3-none-any.whl (7.0 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: py3Dmol, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.50.0\n",
            "    Uninstalling transformers-4.50.0:\n",
            "      Successfully uninstalled transformers-4.50.0\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 py3Dmol-2.4.2 transformers-4.50.3\n"
          ]
        }
      ],
      "source": [
        "# Reference: https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_folding.ipynb#scrollTo=eb29483f\n",
        "\n",
        "! pip install --upgrade transformers py3Dmol accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM1PWgKwB9ca",
        "outputId": "169475a5-616a-4018-cc39-42f7207152aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of EsmForProteinFolding were not initialized from the model checkpoint at facebook/esmfold_v1 and are newly initialized: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "EsmForProteinFolding(\n",
              "  (esm): EsmModel(\n",
              "    (embeddings): EsmEmbeddings(\n",
              "      (word_embeddings): Embedding(33, 2560, padding_idx=1)\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "      (position_embeddings): Embedding(1026, 2560, padding_idx=1)\n",
              "    )\n",
              "    (encoder): EsmEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-35): 36 x EsmLayer(\n",
              "          (attention): EsmAttention(\n",
              "            (self): EsmSelfAttention(\n",
              "              (query): Linear(in_features=2560, out_features=2560, bias=True)\n",
              "              (key): Linear(in_features=2560, out_features=2560, bias=True)\n",
              "              (value): Linear(in_features=2560, out_features=2560, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (rotary_embeddings): RotaryEmbedding()\n",
              "            )\n",
              "            (output): EsmSelfOutput(\n",
              "              (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (LayerNorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (intermediate): EsmIntermediate(\n",
              "            (dense): Linear(in_features=2560, out_features=10240, bias=True)\n",
              "          )\n",
              "          (output): EsmOutput(\n",
              "            (dense): Linear(in_features=10240, out_features=2560, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (LayerNorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (emb_layer_norm_after): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (contact_head): EsmContactPredictionHead(\n",
              "      (regression): Linear(in_features=1440, out_features=1, bias=True)\n",
              "      (activation): Sigmoid()\n",
              "    )\n",
              "  )\n",
              "  (esm_s_mlp): Sequential(\n",
              "    (0): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "    (1): Linear(in_features=2560, out_features=1024, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (embedding): Embedding(23, 1024, padding_idx=0)\n",
              "  (trunk): EsmFoldingTrunk(\n",
              "    (pairwise_positional_embedding): EsmFoldRelativePosition(\n",
              "      (embedding): Embedding(66, 128)\n",
              "    )\n",
              "    (blocks): ModuleList(\n",
              "      (0-47): 48 x EsmFoldTriangularSelfAttentionBlock(\n",
              "        (layernorm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (sequence_to_pair): EsmFoldSequenceToPair(\n",
              "          (layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (proj): Linear(in_features=1024, out_features=128, bias=True)\n",
              "          (o_proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (pair_to_sequence): EsmFoldPairToSequence(\n",
              "          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (linear): Linear(in_features=128, out_features=32, bias=False)\n",
              "        )\n",
              "        (seq_attention): EsmFoldSelfAttention(\n",
              "          (proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
              "          (o_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (g_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        )\n",
              "        (tri_mul_out): EsmFoldTriangleMultiplicativeUpdate(\n",
              "          (linear_a_p): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "          (linear_a_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "          (linear_b_p): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "          (linear_b_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "          (linear_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "          (linear_z): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "          (layer_norm_in): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (layer_norm_out): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "        (tri_mul_in): EsmFoldTriangleMultiplicativeUpdate(\n",
              "          (linear_a_p): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "          (linear_a_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "          (linear_b_p): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "          (linear_b_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "          (linear_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "          (linear_z): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "          (layer_norm_in): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (layer_norm_out): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "        (tri_att_start): EsmFoldTriangleAttention(\n",
              "          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (linear): EsmFoldLinear(in_features=128, out_features=4, bias=False)\n",
              "          (mha): EsmFoldAttention(\n",
              "            (linear_q): EsmFoldLinear(in_features=128, out_features=128, bias=False)\n",
              "            (linear_k): EsmFoldLinear(in_features=128, out_features=128, bias=False)\n",
              "            (linear_v): EsmFoldLinear(in_features=128, out_features=128, bias=False)\n",
              "            (linear_o): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "            (linear_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (tri_att_end): EsmFoldTriangleAttention(\n",
              "          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (linear): EsmFoldLinear(in_features=128, out_features=4, bias=False)\n",
              "          (mha): EsmFoldAttention(\n",
              "            (linear_q): EsmFoldLinear(in_features=128, out_features=128, bias=False)\n",
              "            (linear_k): EsmFoldLinear(in_features=128, out_features=128, bias=False)\n",
              "            (linear_v): EsmFoldLinear(in_features=128, out_features=128, bias=False)\n",
              "            (linear_o): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "            (linear_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "        (mlp_seq): EsmFoldResidueMLP(\n",
              "          (mlp): Sequential(\n",
              "            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (2): ReLU()\n",
              "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (4): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (mlp_pair): EsmFoldResidueMLP(\n",
              "          (mlp): Sequential(\n",
              "            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "            (1): Linear(in_features=128, out_features=512, bias=True)\n",
              "            (2): ReLU()\n",
              "            (3): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (4): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (drop): Dropout(p=0, inplace=False)\n",
              "        (row_drop): EsmFoldDropout(\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (col_drop): EsmFoldDropout(\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (recycle_s_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (recycle_z_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    (recycle_disto): Embedding(15, 128)\n",
              "    (structure_module): EsmFoldStructureModule(\n",
              "      (layer_norm_s): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm_z): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (linear_in): EsmFoldLinear(in_features=384, out_features=384, bias=True)\n",
              "      (ipa): EsmFoldInvariantPointAttention(\n",
              "        (linear_q): EsmFoldLinear(in_features=384, out_features=192, bias=True)\n",
              "        (linear_kv): EsmFoldLinear(in_features=384, out_features=384, bias=True)\n",
              "        (linear_q_points): EsmFoldLinear(in_features=384, out_features=144, bias=True)\n",
              "        (linear_kv_points): EsmFoldLinear(in_features=384, out_features=432, bias=True)\n",
              "        (linear_b): EsmFoldLinear(in_features=128, out_features=12, bias=True)\n",
              "        (linear_out): EsmFoldLinear(in_features=2112, out_features=384, bias=True)\n",
              "        (softmax): Softmax(dim=-1)\n",
              "        (softplus): Softplus(beta=1.0, threshold=20.0)\n",
              "      )\n",
              "      (ipa_dropout): Dropout(p=0.1, inplace=False)\n",
              "      (layer_norm_ipa): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (transition): EsmFoldStructureModuleTransition(\n",
              "        (layers): ModuleList(\n",
              "          (0): EsmFoldStructureModuleTransitionLayer(\n",
              "            (linear_1): EsmFoldLinear(in_features=384, out_features=384, bias=True)\n",
              "            (linear_2): EsmFoldLinear(in_features=384, out_features=384, bias=True)\n",
              "            (linear_3): EsmFoldLinear(in_features=384, out_features=384, bias=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (bb_update): EsmFoldBackboneUpdate(\n",
              "        (linear): EsmFoldLinear(in_features=384, out_features=6, bias=True)\n",
              "      )\n",
              "      (angle_resnet): EsmFoldAngleResnet(\n",
              "        (linear_in): EsmFoldLinear(in_features=384, out_features=128, bias=True)\n",
              "        (linear_initial): EsmFoldLinear(in_features=384, out_features=128, bias=True)\n",
              "        (layers): ModuleList(\n",
              "          (0-1): 2 x EsmFoldAngleResnetBlock(\n",
              "            (linear_1): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "            (linear_2): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (linear_out): EsmFoldLinear(in_features=128, out_features=14, bias=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (trunk2sm_s): Linear(in_features=1024, out_features=384, bias=True)\n",
              "    (trunk2sm_z): Linear(in_features=128, out_features=128, bias=True)\n",
              "  )\n",
              "  (distogram_head): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (ptm_head): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (lm_head): Linear(in_features=1024, out_features=23, bias=True)\n",
              "  (lddt_head): Sequential(\n",
              "    (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    (1): Linear(in_features=384, out_features=128, bias=True)\n",
              "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (3): Linear(in_features=128, out_features=1850, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, EsmForProteinFolding\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esmfold_v1\")\n",
        "model = EsmForProteinFolding.from_pretrained(\"facebook/esmfold_v1\", low_cpu_mem_usage=True)\n",
        "\n",
        "model = model.cuda()\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yfa_ZypCCJBj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lPgS6XpSEGoL"
      },
      "outputs": [],
      "source": [
        "model.trunk.set_chunk_size(64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "_uPIYQ69CKny",
        "outputId": "1bb449a1-1cfd-4418-9883-c3d555d761a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7081\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7987,\n  \"fields\": [\n    {\n      \"column\": \"protein_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7987,\n        \"samples\": [\n          \"ENSP00000380713\",\n          \"ENSP00000264057\",\n          \"ENSP00000339115\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mrna_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7987,\n        \"samples\": [\n          \"ENST00000397583\",\n          \"ENST00000264057\",\n          \"ENST00000343063\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gene_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7987,\n        \"samples\": [\n          \"ENSG00000099849\",\n          \"ENSG00000077044\",\n          \"ENSG00000144488\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7987,\n        \"samples\": [\n          \"MLLGLAAMELKVWVDGIQRVVCGVSEQTTCQEVVIALAQAIGQTGRFVLVQRLREKERQLLPQECPVGAQATCGQFASDVQFVLRRTGPSLAGRPSSDSCPPPERCLIRASLPVKPRAALGCEPRKTLTPEPAPSLSRPGPAAPVTPTPGCCTDLRGLELRVQRNAEELGHEAFWEQELRREQAREREGQARLQALSAATAEHAARLQALDAQARALEAELQLAAEAPGPPSPMASATERLHQDLAVQERQSAEVQGSLALVSRALEAAERALQAQAQELEELNRELRQCNLQQFIQQTGAALPPPPRPDRGPPGTQGPLPPAREESLLGAPSESHAGAQPRPRGGPHDAELLEVAAAPAPEWCPLAAQPQAL\",\n          \"MAAAAGAPPPGPPQPPPPPPPEESSDSEPEAEPGSPQKLIRKVSTSGQIRQKTIIKEGMLTKQNNSFQRSKRRYFKLRGRTLYYAKTAKSIIFDEVDLTDASVAESSTKNVNNSFTVITPCRKLILCADNRKEMEDWIAALKTVQNREHFEPTQYSMDHFSGMHNWYACSHARPTYCNVCREALSGVTSHGLSCEVCKFKAHKRCAVRATNNCKWTTLASIGKDIIEDADGIAMPHQWLEGNLPVSAKCTVCDKTCGSVLRLQDWRCLWCKAMVHTSCKESLLTKCPLGLCKVSVIPPTALNSIDSDGFWKASCPPSCTSPLLVFVNSKSGDNQGVKFLRRFKQLLNPAQVFDLMNGGPHLGLRLFQKFDTFRILVCGGDGSVGWVLSEIDSLNLHKQCQLGVLPLGTGNDLARVLGWGSACDDDTQLPQILEKLERASTKMLDRWSVMAYEAKLPRQASSSTVTEDFSEDSEVQQILFYEDSVAAHLSKILTSDQHSVVISSAKVLCETVKDFVARVGKAYEKTTESSEESEVMAKKCSVLKEKLDSLLKTLDDESQASSSLPNPPPTIAEEAEDGDGSGSICGSTGDRLVASACPARPQIFRPREQLMLRANSLKKAIRQIIEHTEKAVDEQNAQTQEQEGFVLGLSESEEKMDHRVCPPLSHSESFGVPKGRSQRKVSKSPCEKLISKGSLSLGSSASLPPQPGSRDGLPALNTKILYPNVRAGMSGSLPGGSVISRLLINADPFNSEPETLEYYTEKCVMNNYFGIGLDAKISLDFNNKRDEHPEKCRSRTKNMMWYGVLGTKELLHRTYKNLEQKVLLECDGRPIPLPSLQGIAVLNIPSYAGGTNFWGGTKEDDTFAAPSFDDKILEVVAVFGSMQMAVSRVIRLQHHRIAQCRTVKISILGDEGVPVQVDGEAWVQPPGYIRIVHKNRAQTLTRDRAFESTLKSWEDKQKCELPRPPSCSLHPEMLSEEEATQMDQFGQAAGVLIHSIREIAQSHRDMEQELAHAVNASSKSMDRVYGKPRTTEGLNCSFVLEMVNNFRALRSETELLLSGKMALQLDPPQKEQLGSALAEMDRQLRRLADTPWLCQSAEPGDEESVMLDLAKRSRSGKFRLVTKFKKEKNNKNKEAHSSLGAPVHLWGTEEVAAWLEHLSLCEYKDIFTRHDIRGSELLHLERRDLKDLGVTKVGHMKRILCGIKELSRSAPAVEA\",\n          \"MEKQRALVAAKDGDVATLERLLEAGALGPGITDALGAGLVHHATRAGHLDCVKFLVQRAQLPGNQRAHNGATPAHDAAATGSLAELCWLVREGGCGLQDQDASGVSPLHLAARFGHPVLVEWLLHEGHSATLETREGARPLHHAAVSGDLTCLKLLTAAHGSSVNRRTRSGASPLYLACQEGHLHLAQFLVKDCGADVHLRALDGMSALHAAAARGHYSLVVWLVTFTDIGLTARDNEGATALHFAARGGHTPILDRLLLMGTPILRDSWGGTPLHDAAENGQMECCQTLVSHHVDPSLRDEDGYTAADLAEYHGHRDCAQYLREVAQPVPLLMTPPPPPFPPPPLLATRRSLEDGRRGGPGPGNPSPMSLSPAWPGHPDQPLPREQMTSPAPPRIITSATADPEGTETALAGDTSDGLAALQLDGLPSGDIDGLVPTRDERGQPIPEWKRQVMVRKLQARLGAESSAEAQDNGGSSGPTEQAAWRYSQTHQAILGPFGELLTEDDLVYLEKQIADLQLRRRCQEYESELGRLAAELQALLPEPLVSITVNSHFLPRAPGLEVEEASIPAAEPAGSAEASEVAPGVQPLPFWCSHISRLVRSLSLLLKGVHGLVQGDEKPSTRPLQDTCREASASPPRSEAQRQIQEWGVSVRTLRGNFESASGPLCGFNPGPCEPGAQHRQCLSGCWPALPKPRSGLASGEPRPGDTEEASDSGISCEEVPSEAGAAAGPDLASLRKERIIMLFLSHWRRSAYTPALKTVACRTLGARHAGLRGQEAARSPGPPSPPSEGPRLGHLWQQRSTITHLLGNWKAIMAHVPARQLRRLSRQPRGALSPEQFLPHVDGAPVPYSSLSLDLFMLGYFQLLECDLPAEERKLRHLLCFEVFEHLGTHGWEAVRAFHKAVTDEVAAGRRAWTDGFEDIKARFFGSSQRPAWDTEPGRKSGLTLLGPLPHAAVPCSGPEPTAQRLGSRSQQGSFNGEDICGYINRSFAFWKEKEAEMFNFGE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 519,\n        \"min\": 31,\n        \"max\": 7081,\n        \"num_unique_values\": 1631,\n        \"samples\": [\n          933,\n          1801,\n          811\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cdna\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7987,\n        \"samples\": [\n          \"GCGGCGCTGGGGGCGGCAGGTTGCGGCGGCGCCGGAGCGGGTCTCCAGGCTGGCGAGCGCCCAGGTGAGCCGCGCCGGGTCCCCGGTACTTGGGAGCGCGGGGCGCGCCTCGAGCCGGCCGGACGCCGACTCCAACTGGGGAGAGTTTTCCGCGATGCCCGGACGGAGAGCGGGGGCGGCGCCGCACCTGCGCCCGCCCTGCGGAACGGGGACGCCCTGGCTCCCGCCAGGCTGGGGTCGCGGCGCGGGCTTCGGTGCCCGCGGCGGGGACCGGGACTTTCGGGGCGAGCGCAGCGATTAGGCGGCAGCGGCGGGGCTCCCCGGGCTGGCGGGGGCTGCTCAGACCCGGAGTCTGCTCCATCTGCAGGGTCGAGGTCTGGGTTGCGACCCCGAGCGCCTCTGCGGCCTGAGCAGGTCGGGGTGGGGCGTTCCCATGCCGGCGGCCGCGGGGCCTGGCGTGCGGGCGCCTCCGCGCCGCCCGGGGAGGGGGCAGTGTCCTCCGAGCCAGGACAGGCATGTTGTTGGGACTGGCGGCCATGGAGCTGAAGGTGTGGGTGGATGGCATCCAGCGTGTGGTCTGTGGGGTCTCAGAGCAGACCACCTGCCAGGAAGTGGTCATCGCACTAGCCCAAGCAATAGGCCAGACTGGCCGCTTTGTGCTTGTGCAGCGGCTTCGGGAGAAGGAGCGGCAGTTGCTGCCACAAGAGTGTCCAGTGGGCGCCCAGGCCACCTGCGGACAGTTTGCCAGCGATGTCCAGTTTGTCCTGAGGCGCACAGGGCCCAGCCTAGCTGGGAGGCCCTCCTCAGACAGCTGTCCACCCCCGGAACGCTGCCTAATTCGTGCCAGCCTCCCTGTAAAGCCACGGGCTGCGCTGGGCTGTGAGCCCCGCAAAACACTGACCCCCGAGCCAGCCCCCAGCCTCTCACGCCCTGGGCCTGCGGCCCCTGTGACACCCACACCAGGCTGCTGCACAGACCTGCGGGGCCTGGAGCTCAGGGTGCAGAGGAATGCTGAGGAGCTGGGCCATGAGGCCTTCTGGGAGCAAGAGCTGCGCCGGGAGCAGGCCCGGGAGCGAGAGGGACAGGCACGCCTGCAGGCACTAAGTGCGGCCACTGCTGAGCATGCCGCCCGGCTGCAGGCCCTGGACGCTCAGGCCCGTGCCCTGGAGGCTGAGCTGCAGCTGGCAGCGGAGGCCCCTGGGCCCCCCTCACCTATGGCATCTGCCACTGAGCGCCTGCACCAGGACCTGGCTGTTCAGGAGCGGCAGAGTGCGGAGGTGCAGGGCAGCCTGGCTCTGGTGAGCCGGGCCCTGGAGGCAGCAGAGCGAGCCTTGCAGGCTCAGGCTCAGGAGCTGGAGGAGCTGAACCGAGAGCTCCGTCAGTGCAACCTGCAGCAGTTCATCCAGCAGACCGGGGCTGCGCTGCCACCGCCCCCACGGCCTGACAGGGGCCCTCCTGGCACTCAGGGCCCTCTGCCTCCAGCCAGAGAGGAGTCCCTCCTGGGCGCTCCCTCTGAGTCCCATGCTGGTGCCCAGCCTAGGCCCCGAGGTGGCCCCCATGACGCAGAACTCCTGGAGGTAGCAGCAGCTCCTGCCCCAGAGTGGTGTCCTCTGGCAGCCCAGCCCCAGGCTCTGTGACAGCCTAGTGAGGGCTGCAAGACCATCCTGCCCGGACCACAGAAGGAGAGTTGGCGGTCACAGAGGGCTCCTCTGCCAGGCAGTGGGAAGCCCTGGGTTTGGCCTCAGGAGCTGGGGGTGCAGTGGGGGACTGCCCTAGTCCTTGCCAGGTCGCCAGCACCCTGGAGAAGCATGGGGCGTAGCCAGCTCGGAACTTGCCAGGCCCCAAAGGCCACGACTGCCTGTTGGGGACAGGAGATGCATGGACAGTGTGCTCAAGCTGTGGGCATGTGCTTGCCTGCGGGAGAGGTCCTTCACTGTGTGTACACAGCAAGAGCATGTGTGTGCCACTTCCCCTACCCCAACGTGAAAACCTCAATAAACTGCCCGAAGCAGCTTGA\",\n          \"GCGGTGCGCGCGCTGGCCCGGCAGCATGGCGGCGGCGGCGGGCGCCCCTCCGCCGGGTCCCCCGCAACCGCCTCCGCCGCCGCCGCCCGAGGAGTCGTCCGACAGCGAGCCCGAGGCGGAGCCCGGCTCCCCACAGAAGCTCATCCGCAAGGTGTCCACGTCGGGTCAGATCCGACAGAAGACCATCATCAAAGAGGGGATGCTGACCAAACAGAACAATTCATTCCAGCGATCAAAAAGGAGATACTTTAAGCTTCGAGGGCGAACGCTTTACTATGCCAAAACGGCAAAGTCAATCATATTTGATGAGGTGGATCTGACAGATGCCAGCGTAGCTGAATCCAGTACCAAAAACGTCAACAACAGTTTTACGGTCATAACTCCATGCAGGAAGCTCATCTTGTGTGCTGATAACAGAAAAGAAATGGAAGATTGGATTGCAGCATTAAAGACTGTGCAGAACAGGGAGCACTTTGAGCCCACCCAGTACAGCATGGACCACTTCTCAGGGATGCACAATTGGTACGCCTGTTCCCACGCGAGGCCGACCTACTGCAATGTGTGCCGTGAGGCTCTGTCTGGGGTCACGTCGCACGGGCTGTCCTGCGAGGTGTGCAAATTTAAGGCCCACAAGCGCTGTGCTGTGCGTGCAACCAATAACTGCAAGTGGACCACACTGGCCTCGATCGGGAAGGACATCATTGAAGATGCAGATGGGATTGCAATGCCCCACCAGTGGTTGGAAGGAAACCTACCTGTGAGCGCCAAGTGCACTGTGTGCGACAAGACCTGTGGCAGTGTGCTGCGCCTGCAGGACTGGCGCTGCCTCTGGTGCAAGGCCATGGTTCACACATCGTGTAAAGAATCCTTGCTGACCAAGTGCCCACTTGGCCTGTGCAAAGTGTCAGTCATCCCACCCACGGCTCTCAACAGCATCGACTCCGATGGGTTCTGGAAGGCCAGCTGTCCTCCTTCTTGCACAAGCCCACTGTTGGTCTTCGTCAATTCAAAAAGTGGGGACAACCAGGGTGTGAAGTTCCTCAGAAGATTCAAACAGCTACTAAACCCCGCCCAGGTCTTCGACCTCATGAACGGAGGCCCACACCTCGGCTTACGGTTATTCCAGAAGTTTGACACATTCCGGATTCTGGTTTGTGGCGGGGATGGAAGTGTTGGCTGGGTCCTCTCCGAAATCGACAGCCTCAACCTTCATAAACAGTGTCAGCTGGGAGTGCTGCCGCTCGGCACAGGGAACGACTTGGCCCGAGTACTGGGCTGGGGCTCAGCCTGCGATGACGACACCCAGCTCCCCCAGATCTTGGAGAAGTTGGAGAGAGCCAGCACCAAGATGCTGGACAGGTGGAGCGTCATGGCATACGAGGCCAAGCTCCCCCGGCAGGCCTCCTCCTCTACCGTCACCGAAGACTTCAGCGAGGATTCCGAGGTACAGCAGATTCTCTTCTATGAAGACTCGGTTGCAGCCCACCTTTCTAAAATCCTCACCTCGGACCAGCACTCGGTGGTCATCTCCTCGGCCAAAGTGCTCTGTGAGACGGTGAAGGACTTCGTGGCACGGGTGGGGAAGGCCTATGAGAAGACGACCGAGAGCTCGGAGGAGTCAGAGGTCATGGCCAAGAAGTGCTCTGTCCTGAAAGAGAAGCTGGATTCCCTTCTCAAGACCTTGGACGATGAGTCCCAGGCCTCGTCCTCTCTGCCCAACCCGCCCCCCACCATTGCCGAGGAGGCTGAAGATGGAGATGGGTCGGGCAGCATCTGCGGTTCCACCGGAGACCGCTTGGTGGCATCAGCTTGCCCGGCCCGGCCGCAGATATTCCGGCCTCGAGAACAGCTCATGCTGAGAGCCAACAGCCTGAAGAAAGCAATTCGTCAGATCATAGAACACACAGAAAAAGCTGTCGATGAGCAGAATGCCCAGACCCAGGAGCAGGAGGGCTTCGTCCTGGGCCTCTCTGAGTCAGAGGAGAAGATGGACCACAGAGTGTGCCCACCACTGTCCCACAGCGAGAGCTTCGGGGTCCCCAAGGGGAGGAGCCAGCGCAAAGTGTCGAAATCTCCGTGTGAAAAGCTGATCAGCAAAGGGAGTCTGTCCCTAGGCAGTTCTGCTTCCCTTCCGCCCCAGCCGGGAAGCCGGGACGGCCTGCCTGCGCTCAACACCAAGATCCTGTACCCAAATGTCCGGGCTGGAATGTCTGGTTCCTTACCCGGTGGCTCAGTCATCAGTCGCCTGTTAATTAATGCTGATCCCTTCAACTCTGAACCAGAAACCCTAGAGTATTACACGGAGAAATGTGTCATGAACAACTATTTTGGCATTGGCCTGGATGCGAAGATATCCCTGGACTTTAACAACAAGCGCGATGAGCACCCAGAGAAGTGCAGGAGCCGAACCAAGAACATGATGTGGTATGGAGTTCTTGGAACCAAAGAGTTGCTGCACAGAACCTACAAGAACCTGGAGCAAAAGGTCTTGCTGGAGTGTGACGGGCGACCCATCCCACTCCCCAGTCTTCAGGGAATTGCTGTCCTTAACATTCCCAGCTATGCCGGAGGAACCAACTTCTGGGGGGGTACCAAGGAAGATGATACTTTCGCAGCTCCATCATTCGATGACAAGATTCTGGAGGTGGTCGCCGTGTTCGGCAGCATGCAGATGGCCGTCTCTCGAGTCATCAGGCTACAGCATCATCGGATCGCCCAGTGTCGCACGGTGAAGATCTCCATCCTTGGGGATGAGGGCGTGCCTGTGCAGGTGGACGGAGAGGCCTGGGTCCAGCCGCCAGGGTACATTCGGATTGTCCACAAGAACCGGGCACAGACACTGACCAGAGACAGGGCATTTGAGAGCACCCTGAAGTCCTGGGAAGACAAGCAGAAGTGCGAGCTGCCCCGCCCTCCATCCTGTTCCCTGCACCCGGAGATGCTGTCCGAGGAGGAGGCCACCCAGATGGACCAGTTTGGGCAGGCAGCAGGGGTCCTCATTCACAGTATCCGAGAAATAGCTCAGTCTCACCGGGACATGGAGCAGGAACTGGCCCACGCCGTCAATGCCAGCTCCAAGTCCATGGACCGTGTGTATGGCAAGCCCAGAACCACAGAGGGGCTCAACTGCAGCTTCGTCCTGGAAATGGTGAATAACTTCAGAGCTCTGCGCAGTGAGACGGAGCTGCTGCTGTCTGGGAAGATGGCCCTGCAGCTGGATCCGCCTCAGAAGGAGCAGCTGGGGAGTGCTCTTGCCGAGATGGACCGACAGCTCAGGAGGCTGGCAGACACCCCGTGGCTCTGCCAGTCCGCAGAGCCCGGCGACGAAGAGAGTGTGATGCTGGATCTTGCCAAGCGCAGTCGCAGTGGTAAATTCCGCCTCGTGACCAAGTTTAAAAAGGAGAAAAACAACAAGAACAAAGAAGCTCACAGTAGCCTGGGAGCCCCGGTTCACCTCTGGGGGACAGAGGAGGTTGCTGCCTGGCTGGAGCACCTCAGTCTCTGTGAGTATAAGGACATCTTCACACGGCACGACATCCGGGGCTCTGAGCTCCTGCACCTGGAGCGGAGGGACCTCAAGGACCTGGGCGTGACCAAGGTGGGCCACATGAAGAGGATCCTGTGTGGCATCAAGGAGCTGAGCCGCAGCGCCCCCGCCGTCGAGGCCTAGCCTCTGTCCTCTCAGCCTGTGGCCTCCACATCCCCGCCGCCGAGGCCTAGCCTCCGCCCTCTCAGCCTGTGGCCTCTGCGCCTCCTGCCACTGAGGCCCTGGGCAGATGCTGCAGCCCGCCCCCTTCTCATGGTGCTACTTCCTCTGTCAGCTACAGAAAGCCTCCGTGACACCGTCCACCAGAGCTCTGGGGTCTCGAACATAACAACACAGCTACCTTTGAAACAACACTTTCTCCAGCTCAGAGTCACCTGGGGCACATGTGTCACGGCCACTCAGCTCTCGCCCGCCTGTGCTGTGGGCCAGGGAATCCAGCGGCGTCTGGCCTCCTGGGCACTGCTTGCCTGGCCTCGTGCTTGGATTGTCCCGGGGGCTCCTCTCCGTGTGTCCTTCTGTGGCCGCACCGTGTGGCTCCGCCTCCTGGCCCCCAGCCAGTTCTCAGAAACGTGGCTGGGGCCCAGCACAGCAGCCTGCAAGGGCCCCTGTTTGTTGATGCAGCTTTTGTTGAACAAAAATCGTGCTCTTTCCTGGTTTGAAAGTAGCATGGATGTTTCCAGTCTTGTTGATTGTAATTTGACGTGAAGAGAAAAAAAAATTCCTCCTGCGTGAGCCAAGGCAGCGGGTGCTGTTTCCCAGGCGGGGAGCCCCTCCCTGGGTGTCACAGGGCCTGTGCTCCTCCCTCCTCCATCCTCTCTCCTCCCGCTCCTCCCTCCCCCCACTGTGGGCTGGGGACGCCTGCCCTTCTGTCTCCGGACGCTCTAGGCGAGTTCAGCTTGGGGTGTGAGTGAGACAGCTTGCCAGCTGCATCCCTGCAGACAGAGGATGTGTGTCCACATGAGTGTTTCTGTGTGGGAAATGCTTCCTGGCTCTGGGAAACTTTTTCTGCCCATTCTGTGGTTCCCAGGGAGCGTGGCCCTGGTGGGCCAGGGGTGGTTTGACCTCTTCAGCCCGTCCGGTGGCCTGGAGGCCGGAGGCTCTCCTGAGTGTCTGCCCCTGCAGTGGCTTCTTGTCGCCTGCTGCTGGGCGTGATGTCGCTGGAGGTGCTGGCAGGGACTCTGATTTGGTGGTCCGCGCTGCCCCTGCCCTGCCTCTGTCCTGGCTCTGAACTAGTAGATGATGGTGCCAGAGGGCAGGGAGCTCGCCTGGGGAGAGGGCTGTGCCCCGTAGGGACAGTGCCCAGGTGAAGGATGCCCCTGGTCCTCCAGGGCACTGACTTTGCCCTTTTTTCCCGTTGATAGTCATGGCTCAGAGGTGCTTGTAAATGTCTTGGGAAGAGGTTTCTGTAACCCCTGCCCTGGTGTGAGGAGGAAATGGCTCTGGCCTGGCTGCCTGGCCGTGGCTTCTCTTTGGCTCCCAAAGAGAAGGACAGTGTTGGGAGTATCTGCCGTGGCTTCTCTTTGGCTCCCAAAGAGAAGGACAGTGTTGGGAGTATCTGCCGGCGCTGTCCAGGTCCTTTAGTCAGCGTCACTCCATCTGATGTGCAGAAGCTGGGCTGCACCTGCGGGGGTGGGCATAGACCGGGCTGGGTCTGCAGCAGCCCCTGGTCCTGAGCAGGCGGCAGTGAACAGCACTGGCCCACCTCCCACTCACAGCCCCTCTGTCCCCTCTGCAGTGCACCCAGGTGGGCCCCTCTGCGTGCCTTTGGGTGCTCCCCTCTCGTGGTCGTTCTGGCCCGAGGCCCTTAGAGTATGGAGGCTGAGCCAGGCCTTGGGTTTCCCCAGCACAGCCTCCTGTCGCTGCATGCGACGTGTTGGGATTTTTGGATGAAAGACTCTCCCACGCTCTGTTGGTGGACTTAGCTGCCTCACTGGAAGTGATGTGGGTGGAAGGTGGTTGTATGTTACCTTTTCCACCTCTCATTGTTTTCCCCAGAACATTGTAGATGGGGGTTGGCAGAGGGAGAAATAAGCCAGCCACGGCAGTCGCTTGGTTTCCCAGGTGGAATGGGCTAACACAGGAGATGATGGGAACCTGTCCCGCAGTCCCTGCATGACCATTGGCCCTGCTGGCCTGGCGATGTGGGCATCCTGGGGTTCTTAGGGTCCCAGAACAAGCCCCAGGCAAGCTGGAACTTGGGTGGGGAGGGGACATGAGGAGGATAAACAGCTGACTGTGGCTTCAAGGACATCAGGGCCACCCCAAGTCCTCAGTGTCCTACTCCTGGCAAGGAGTTGGGTTTGGATCAAAAGTGTTTAAAATTAATATGTTGTCAGTGATTAGAACAACACTGTTTACATAAAAACCATTTTTCTAATTCTAACAAGTTAGAATGTGAGGAAGGAATGAACATGAGTGTTTAGGAACCTGCCCTTTGGTGCTGGGCTGGCGTCCCGCACTGGGGTGTCCTCGCTGTCTGGGGGCTGCTCTGCTGCCCCGGCCCAGGTCCCCTTGTGGTGTTGCCAGACGGGCCTCATGGTCTGCTGTGCAGAGAGAGGCAGGAAGGATCCCTGAAGAGTCTTGGAGAAAAGGTTCTGTGCCCTCAGGTGGGGCTTACCCCCTCGTATTTATAATCTTAATTTATATAGTGACCACCGTGGAAACAAACGCCTCTTGTATTGTCATGTACATAGTCCATACCTGAGTGCTGTACATAAGTTGTTCTGTGTATAAATAAAACAAGCCTGTTTTTGATCTTCCA\",\n          \"AGAGCCGGCAGCTTCATCCACGTCTGAAACAGGAAGCCCCAGCCTGTGCATGAGTCGCCACTGAGAGCCCGGGCCAGAGGATGGAGAAGCAGCGGGCACTCGTGGCCGCCAAGGATGGGGATGTGGCGACGTTGGAGCGGCTGCTGGAGGCTGGCGCCCTGGGCCCGGGCATCACCGATGCTCTGGGGGCCGGCCTGGTTCACCACGCCACCCGGGCTGGCCACCTGGACTGCGTCAAGTTCTTGGTGCAGCGGGCCCAGCTGCCCGGCAACCAGCGGGCCCACAACGGGGCCACCCCAGCGCATGACGCCGCTGCCACGGGCAGCCTGGCCGAGCTGTGCTGGCTGGTCCGCGAGGGGGGCTGCGGTCTGCAGGACCAAGATGCCTCGGGCGTCTCCCCGCTGCACCTGGCCGCCCGTTTTGGACACCCAGTGCTGGTGGAGTGGCTGCTCCACGAGGGCCACTCGGCCACGCTAGAGACCCGGGAGGGAGCCCGGCCGCTGCACCACGCTGCCGTCAGTGGGGACCTGACCTGCCTCAAGCTCCTGACAGCCGCGCATGGCAGCAGCGTGAACCGGCGGACACGCAGTGGCGCCTCCCCACTCTACCTGGCCTGCCAGGAGGGCCACCTGCACCTGGCCCAGTTCCTGGTGAAGGACTGTGGCGCTGACGTGCACCTTCGTGCTCTCGATGGCATGAGCGCCCTGCACGCTGCCGCCGCCCGTGGCCACTACTCCCTCGTCGTCTGGCTGGTCACATTCACCGACATCGGACTCACGGCACGGGACAATGAGGGGGCCACGGCCCTGCACTTTGCAGCCCGAGGCGGCCACACGCCCATTCTAGACCGACTCCTGCTCATGGGTACCCCCATCCTGAGAGACTCCTGGGGTGGGACCCCCCTCCACGACGCAGCAGAGAACGGGCAGATGGAGTGCTGCCAGACCCTAGTCTCCCACCACGTGGACCCCTCCCTGCGGGATGAAGATGGTTACACGGCGGCAGACCTGGCGGAGTACCATGGACACCGGGACTGCGCCCAGTACCTGCGGGAGGTGGCCCAGCCGGTGCCCCTGCTGATGACGCCCCCACCACCACCGTTCCCCCCACCTCCACTGTTGGCCACGAGGCGCTCCCTGGAGGATGGAAGAAGAGGAGGCCCAGGGCCAGGGAACCCCAGCCCCATGTCCCTCAGCCCGGCCTGGCCTGGCCATCCTGACCAGCCTCTTCCCAGGGAGCAGATGACCAGCCCGGCCCCTCCGAGGATCATCACCAGTGCCACGGCTGACCCCGAGGGGACAGAGACGGCGCTGGCGGGGGACACCTCAGATGGCCTGGCCGCACTACAGCTGGATGGGCTGCCCTCAGGCGACATCGACGGGCTGGTGCCCACGCGGGATGAGCGCGGCCAGCCCATCCCAGAGTGGAAGCGGCAGGTGATGGTGCGGAAGCTGCAGGCGCGCCTGGGCGCAGAGAGCTCCGCAGAGGCCCAGGACAATGGTGGGAGCTCAGGCCCCACGGAGCAGGCGGCCTGGAGGTACTCACAGACTCATCAGGCCATCCTGGGGCCCTTTGGGGAGCTGCTGACAGAGGATGACCTGGTCTACCTGGAGAAGCAGATTGCAGACCTGCAGCTTCGGCGCCGCTGTCAGGAGTATGAGAGTGAGCTGGGCCGGTTGGCGGCTGAGCTGCAGGCCCTGCTGCCCGAGCCCCTGGTCAGCATCACGGTCAACAGCCACTTCCTGCCCCGGGCGCCCGGACTGGAGGTTGAGGAGGCCTCAATCCCAGCGGCTGAGCCCGCAGGGTCTGCGGAGGCCTCAGAGGTGGCCCCCGGGGTGCAGCCCCTGCCCTTCTGGTGCAGCCACATCTCCCGCCTGGTACGCAGCCTGTCCCTGCTGCTGAAGGGCGTGCATGGGCTAGTACAGGGGGATGAGAAGCCATCCACCCGGCCCCTGCAGGACACCTGCAGGGAGGCCTCGGCCAGCCCCCCTCGGAGCGAGGCCCAGCGCCAGATCCAGGAGTGGGGGGTGTCTGTGCGGACGCTGCGGGGCAACTTCGAGTCGGCCTCTGGCCCACTCTGTGGCTTCAACCCTGGCCCCTGCGAGCCGGGGGCCCAGCACAGGCAGTGCCTGAGTGGCTGCTGGCCAGCCCTGCCTAAGCCCCGCAGTGGCCTGGCTTCAGGGGAGCCCAGGCCTGGCGACACAGAGGAGGCCAGCGACTCTGGCATCAGCTGCGAGGAGGTGCCATCAGAGGCGGGTGCCGCAGCCGGCCCAGACCTGGCCAGCCTGCGCAAGGAGCGCATCATCATGCTCTTCCTCAGCCACTGGAGGAGATCGGCCTACACGCCGGCCCTCAAGACAGTGGCCTGCAGGACCCTAGGAGCCCGCCACGCGGGGTTGCGGGGCCAGGAGGCCGCCAGGAGCCCTGGGCCACCCTCCCCGCCCAGCGAGGGCCCCCGGCTGGGCCACCTGTGGCAGCAGCGCAGCACCATCACCCACCTGCTGGGCAACTGGAAGGCCATCATGGCTCACGTGCCCGCCCGGCAGCTGCGGCGGCTGAGCCGGCAGCCCCGCGGGGCTTTGTCCCCCGAGCAGTTCCTGCCCCACGTGGACGGGGCTCCGGTGCCCTACAGCAGCCTCTCACTGGATCTCTTCATGCTGGGTTACTTCCAGCTGCTGGAGTGCGACCTGCCGGCGGAGGAGCGGAAGCTGCGCCACCTGCTGTGCTTCGAGGTCTTCGAGCACCTGGGCACCCACGGCTGGGAGGCTGTGCGCGCCTTCCACAAGGCCGTGACCGACGAGGTGGCCGCCGGCCGCCGGGCCTGGACCGACGGCTTCGAGGACATCAAAGCCCGCTTCTTTGGCTCCAGCCAGCGTCCCGCCTGGGATACGGAGCCTGGCCGCAAGTCAGGTCTGACCCTGCTCGGGCCCCTGCCTCACGCCGCCGTCCCCTGCAGCGGCCCTGAGCCCACAGCACAGCGGCTGGGGTCCCGCTCCCAGCAGGGCAGCTTCAACGGTGAGGACATCTGCGGCTACATCAACCGCAGCTTTGCCTTCTGGAAGGAGAAGGAAGCTGAGATGTTCAACTTTGGAGAATGACCCTACTGGCAGCCTGCTTTCCAGAATGTGGTTTGGGGGTGACTTGGAGTTTCTCTTTTCTTTTCCTTGCTCACACCCTTGGTGTTCAGGTGAGCCGGGCAAGGCTGCCTCCAGTCCTACCAGTTATCGGAGGCTGCGGGACTGTTCTGTTGTGGCATGGTTCTCCTCCGAGCTGGGACTCAGACTCCTTCTCACCACTGCACCCAGGAAGCCCCTTGGCAGGTCCTGAAGTGAGGCAATGGGCCACCCCAGTCCAGGGCACCTCTGCCCAGCCGGCCCCCGAGACCTGGGATGCTGCCTGTTTCTCACTTGTCCTTCCCCAGTGTCACCAGTTCCCTTGGCGTCCTGTCCCTCAGTTTCTGTGGTGCTGGTGGCCTCGGCCACATCCATCTTTCATGTGAGTCTGAGGTGGCCCCAGGCCCTGGTCCTGCCCCTGTTTCTCCTGCTGACCTTGGGTCACACCCCTTCACCTCCCATCTGTGAATTTGGGGGAGCTGGAGTGATTCCGAGGACAGATTCCATGGGCAGGAGGCCTTCCTGCCAGGCCATCCCTGCTGGTCACACACCGATGCCCGCCAGGCCAGTGCCCCAGCCCAGGGTGCTCCGGAGGCCCTGCTTCCTCAAAGGAGGCTCCCCATGGGGCCCCTGTCCTCCAGCCTGACCAGCCCTGGCCTAGTCGTGGGCCCCAGCAAGGCTGGAGAGCAGGGACGTGGGAGTAGCAGTGGCTGAGAGAGTCCTCCAGGCAGGGTGGCTGGTGCCCACTCTCAAAGGCTGCTGCACACAGAGGAGAATGCCGGCAGGGGTGGGCAGCAGCCAGACCTCAGGGGGGCGTGGATACTCCGTGAGGGCACCTGGGTGTCACCCACAGTGCACCTCTTCACAGGGGCCTGGGTACTGGAGGGAGGGATACAGGAAGGGAGATGGATTCCGTCCTCGGGGGCTCTGGGTGCTGCGGAGTATTCCTGGGCATGGTGCTGGGCATGGCTGGCATAGGGTGTGGCTTGTCCCCAGCTTCTGATGGCAGCCAGGAGAATGGGTCATCACCCAGGCTCTGGGGCTGAGGAGGGCTGGGCCCAAGCCCACAGGGACTTTGGAGGTGGGGCTCTGCAGCTGTGAGATGGCCCAGCAGGGAGTGGCAGGGACGGGAGGCTTCAGGAATATTCCTCCTGGCATCCAGGCCCCCTGGGACAGAGGAGGGTGCAGTCAGGCGACAGGCTTATCAGGACTCCCTGCCTCAATCCCTGGGGATTGTCCAGGCAAAACCTGGAGGGCAGCGGGCAAGCTGTTGGATGGAACAGAGAGACCCTCGCAGCTGACTAGGGCCCAAGGGGACGGACACTCAAGAAGATGTAAAATTGGGAGGGGTGGTATTGGCCATTGGGGCAGGCAGGGCCGGGAAGGGAAGTAGCACCGGCCGCAGCCCCAAGCCAGTGGCTTTTCCACAAGGGCCTATCCTGCAGCCGGCCCGCTCCGGCTTCCTCCACTGCTGAAGACCCTGCTGTAGAGCTGAAGCTGAACATGTGTTTGCTAAATAAAGATTCCCATTCCTAGCGCA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"5utr\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7979,\n        \"samples\": [\n          \"AGAGCCGGCAGCTTCATCCACGTCTGAAACAGGAAGCCCCAGCCTGTGCATGAGTCGCCACTGAGAGCCCGGGCCAGAGG\",\n          \"AGAAGCCCCACGACG\",\n          \"AGAGGCGGGTCGCAGCGGCGCAGAGGAGGTCAGCTGCGGGAGCGTTTCCGGGGACGGTGCCGCC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cds\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7987,\n        \"samples\": [\n          \"ATGTTGTTGGGACTGGCGGCCATGGAGCTGAAGGTGTGGGTGGATGGCATCCAGCGTGTGGTCTGTGGGGTCTCAGAGCAGACCACCTGCCAGGAAGTGGTCATCGCACTAGCCCAAGCAATAGGCCAGACTGGCCGCTTTGTGCTTGTGCAGCGGCTTCGGGAGAAGGAGCGGCAGTTGCTGCCACAAGAGTGTCCAGTGGGCGCCCAGGCCACCTGCGGACAGTTTGCCAGCGATGTCCAGTTTGTCCTGAGGCGCACAGGGCCCAGCCTAGCTGGGAGGCCCTCCTCAGACAGCTGTCCACCCCCGGAACGCTGCCTAATTCGTGCCAGCCTCCCTGTAAAGCCACGGGCTGCGCTGGGCTGTGAGCCCCGCAAAACACTGACCCCCGAGCCAGCCCCCAGCCTCTCACGCCCTGGGCCTGCGGCCCCTGTGACACCCACACCAGGCTGCTGCACAGACCTGCGGGGCCTGGAGCTCAGGGTGCAGAGGAATGCTGAGGAGCTGGGCCATGAGGCCTTCTGGGAGCAAGAGCTGCGCCGGGAGCAGGCCCGGGAGCGAGAGGGACAGGCACGCCTGCAGGCACTAAGTGCGGCCACTGCTGAGCATGCCGCCCGGCTGCAGGCCCTGGACGCTCAGGCCCGTGCCCTGGAGGCTGAGCTGCAGCTGGCAGCGGAGGCCCCTGGGCCCCCCTCACCTATGGCATCTGCCACTGAGCGCCTGCACCAGGACCTGGCTGTTCAGGAGCGGCAGAGTGCGGAGGTGCAGGGCAGCCTGGCTCTGGTGAGCCGGGCCCTGGAGGCAGCAGAGCGAGCCTTGCAGGCTCAGGCTCAGGAGCTGGAGGAGCTGAACCGAGAGCTCCGTCAGTGCAACCTGCAGCAGTTCATCCAGCAGACCGGGGCTGCGCTGCCACCGCCCCCACGGCCTGACAGGGGCCCTCCTGGCACTCAGGGCCCTCTGCCTCCAGCCAGAGAGGAGTCCCTCCTGGGCGCTCCCTCTGAGTCCCATGCTGGTGCCCAGCCTAGGCCCCGAGGTGGCCCCCATGACGCAGAACTCCTGGAGGTAGCAGCAGCTCCTGCCCCAGAGTGGTGTCCTCTGGCAGCCCAGCCCCAGGCTCTGTGA\",\n          \"ATGGCGGCGGCGGCGGGCGCCCCTCCGCCGGGTCCCCCGCAACCGCCTCCGCCGCCGCCGCCCGAGGAGTCGTCCGACAGCGAGCCCGAGGCGGAGCCCGGCTCCCCACAGAAGCTCATCCGCAAGGTGTCCACGTCGGGTCAGATCCGACAGAAGACCATCATCAAAGAGGGGATGCTGACCAAACAGAACAATTCATTCCAGCGATCAAAAAGGAGATACTTTAAGCTTCGAGGGCGAACGCTTTACTATGCCAAAACGGCAAAGTCAATCATATTTGATGAGGTGGATCTGACAGATGCCAGCGTAGCTGAATCCAGTACCAAAAACGTCAACAACAGTTTTACGGTCATAACTCCATGCAGGAAGCTCATCTTGTGTGCTGATAACAGAAAAGAAATGGAAGATTGGATTGCAGCATTAAAGACTGTGCAGAACAGGGAGCACTTTGAGCCCACCCAGTACAGCATGGACCACTTCTCAGGGATGCACAATTGGTACGCCTGTTCCCACGCGAGGCCGACCTACTGCAATGTGTGCCGTGAGGCTCTGTCTGGGGTCACGTCGCACGGGCTGTCCTGCGAGGTGTGCAAATTTAAGGCCCACAAGCGCTGTGCTGTGCGTGCAACCAATAACTGCAAGTGGACCACACTGGCCTCGATCGGGAAGGACATCATTGAAGATGCAGATGGGATTGCAATGCCCCACCAGTGGTTGGAAGGAAACCTACCTGTGAGCGCCAAGTGCACTGTGTGCGACAAGACCTGTGGCAGTGTGCTGCGCCTGCAGGACTGGCGCTGCCTCTGGTGCAAGGCCATGGTTCACACATCGTGTAAAGAATCCTTGCTGACCAAGTGCCCACTTGGCCTGTGCAAAGTGTCAGTCATCCCACCCACGGCTCTCAACAGCATCGACTCCGATGGGTTCTGGAAGGCCAGCTGTCCTCCTTCTTGCACAAGCCCACTGTTGGTCTTCGTCAATTCAAAAAGTGGGGACAACCAGGGTGTGAAGTTCCTCAGAAGATTCAAACAGCTACTAAACCCCGCCCAGGTCTTCGACCTCATGAACGGAGGCCCACACCTCGGCTTACGGTTATTCCAGAAGTTTGACACATTCCGGATTCTGGTTTGTGGCGGGGATGGAAGTGTTGGCTGGGTCCTCTCCGAAATCGACAGCCTCAACCTTCATAAACAGTGTCAGCTGGGAGTGCTGCCGCTCGGCACAGGGAACGACTTGGCCCGAGTACTGGGCTGGGGCTCAGCCTGCGATGACGACACCCAGCTCCCCCAGATCTTGGAGAAGTTGGAGAGAGCCAGCACCAAGATGCTGGACAGGTGGAGCGTCATGGCATACGAGGCCAAGCTCCCCCGGCAGGCCTCCTCCTCTACCGTCACCGAAGACTTCAGCGAGGATTCCGAGGTACAGCAGATTCTCTTCTATGAAGACTCGGTTGCAGCCCACCTTTCTAAAATCCTCACCTCGGACCAGCACTCGGTGGTCATCTCCTCGGCCAAAGTGCTCTGTGAGACGGTGAAGGACTTCGTGGCACGGGTGGGGAAGGCCTATGAGAAGACGACCGAGAGCTCGGAGGAGTCAGAGGTCATGGCCAAGAAGTGCTCTGTCCTGAAAGAGAAGCTGGATTCCCTTCTCAAGACCTTGGACGATGAGTCCCAGGCCTCGTCCTCTCTGCCCAACCCGCCCCCCACCATTGCCGAGGAGGCTGAAGATGGAGATGGGTCGGGCAGCATCTGCGGTTCCACCGGAGACCGCTTGGTGGCATCAGCTTGCCCGGCCCGGCCGCAGATATTCCGGCCTCGAGAACAGCTCATGCTGAGAGCCAACAGCCTGAAGAAAGCAATTCGTCAGATCATAGAACACACAGAAAAAGCTGTCGATGAGCAGAATGCCCAGACCCAGGAGCAGGAGGGCTTCGTCCTGGGCCTCTCTGAGTCAGAGGAGAAGATGGACCACAGAGTGTGCCCACCACTGTCCCACAGCGAGAGCTTCGGGGTCCCCAAGGGGAGGAGCCAGCGCAAAGTGTCGAAATCTCCGTGTGAAAAGCTGATCAGCAAAGGGAGTCTGTCCCTAGGCAGTTCTGCTTCCCTTCCGCCCCAGCCGGGAAGCCGGGACGGCCTGCCTGCGCTCAACACCAAGATCCTGTACCCAAATGTCCGGGCTGGAATGTCTGGTTCCTTACCCGGTGGCTCAGTCATCAGTCGCCTGTTAATTAATGCTGATCCCTTCAACTCTGAACCAGAAACCCTAGAGTATTACACGGAGAAATGTGTCATGAACAACTATTTTGGCATTGGCCTGGATGCGAAGATATCCCTGGACTTTAACAACAAGCGCGATGAGCACCCAGAGAAGTGCAGGAGCCGAACCAAGAACATGATGTGGTATGGAGTTCTTGGAACCAAAGAGTTGCTGCACAGAACCTACAAGAACCTGGAGCAAAAGGTCTTGCTGGAGTGTGACGGGCGACCCATCCCACTCCCCAGTCTTCAGGGAATTGCTGTCCTTAACATTCCCAGCTATGCCGGAGGAACCAACTTCTGGGGGGGTACCAAGGAAGATGATACTTTCGCAGCTCCATCATTCGATGACAAGATTCTGGAGGTGGTCGCCGTGTTCGGCAGCATGCAGATGGCCGTCTCTCGAGTCATCAGGCTACAGCATCATCGGATCGCCCAGTGTCGCACGGTGAAGATCTCCATCCTTGGGGATGAGGGCGTGCCTGTGCAGGTGGACGGAGAGGCCTGGGTCCAGCCGCCAGGGTACATTCGGATTGTCCACAAGAACCGGGCACAGACACTGACCAGAGACAGGGCATTTGAGAGCACCCTGAAGTCCTGGGAAGACAAGCAGAAGTGCGAGCTGCCCCGCCCTCCATCCTGTTCCCTGCACCCGGAGATGCTGTCCGAGGAGGAGGCCACCCAGATGGACCAGTTTGGGCAGGCAGCAGGGGTCCTCATTCACAGTATCCGAGAAATAGCTCAGTCTCACCGGGACATGGAGCAGGAACTGGCCCACGCCGTCAATGCCAGCTCCAAGTCCATGGACCGTGTGTATGGCAAGCCCAGAACCACAGAGGGGCTCAACTGCAGCTTCGTCCTGGAAATGGTGAATAACTTCAGAGCTCTGCGCAGTGAGACGGAGCTGCTGCTGTCTGGGAAGATGGCCCTGCAGCTGGATCCGCCTCAGAAGGAGCAGCTGGGGAGTGCTCTTGCCGAGATGGACCGACAGCTCAGGAGGCTGGCAGACACCCCGTGGCTCTGCCAGTCCGCAGAGCCCGGCGACGAAGAGAGTGTGATGCTGGATCTTGCCAAGCGCAGTCGCAGTGGTAAATTCCGCCTCGTGACCAAGTTTAAAAAGGAGAAAAACAACAAGAACAAAGAAGCTCACAGTAGCCTGGGAGCCCCGGTTCACCTCTGGGGGACAGAGGAGGTTGCTGCCTGGCTGGAGCACCTCAGTCTCTGTGAGTATAAGGACATCTTCACACGGCACGACATCCGGGGCTCTGAGCTCCTGCACCTGGAGCGGAGGGACCTCAAGGACCTGGGCGTGACCAAGGTGGGCCACATGAAGAGGATCCTGTGTGGCATCAAGGAGCTGAGCCGCAGCGCCCCCGCCGTCGAGGCCTAG\",\n          \"ATGGAGAAGCAGCGGGCACTCGTGGCCGCCAAGGATGGGGATGTGGCGACGTTGGAGCGGCTGCTGGAGGCTGGCGCCCTGGGCCCGGGCATCACCGATGCTCTGGGGGCCGGCCTGGTTCACCACGCCACCCGGGCTGGCCACCTGGACTGCGTCAAGTTCTTGGTGCAGCGGGCCCAGCTGCCCGGCAACCAGCGGGCCCACAACGGGGCCACCCCAGCGCATGACGCCGCTGCCACGGGCAGCCTGGCCGAGCTGTGCTGGCTGGTCCGCGAGGGGGGCTGCGGTCTGCAGGACCAAGATGCCTCGGGCGTCTCCCCGCTGCACCTGGCCGCCCGTTTTGGACACCCAGTGCTGGTGGAGTGGCTGCTCCACGAGGGCCACTCGGCCACGCTAGAGACCCGGGAGGGAGCCCGGCCGCTGCACCACGCTGCCGTCAGTGGGGACCTGACCTGCCTCAAGCTCCTGACAGCCGCGCATGGCAGCAGCGTGAACCGGCGGACACGCAGTGGCGCCTCCCCACTCTACCTGGCCTGCCAGGAGGGCCACCTGCACCTGGCCCAGTTCCTGGTGAAGGACTGTGGCGCTGACGTGCACCTTCGTGCTCTCGATGGCATGAGCGCCCTGCACGCTGCCGCCGCCCGTGGCCACTACTCCCTCGTCGTCTGGCTGGTCACATTCACCGACATCGGACTCACGGCACGGGACAATGAGGGGGCCACGGCCCTGCACTTTGCAGCCCGAGGCGGCCACACGCCCATTCTAGACCGACTCCTGCTCATGGGTACCCCCATCCTGAGAGACTCCTGGGGTGGGACCCCCCTCCACGACGCAGCAGAGAACGGGCAGATGGAGTGCTGCCAGACCCTAGTCTCCCACCACGTGGACCCCTCCCTGCGGGATGAAGATGGTTACACGGCGGCAGACCTGGCGGAGTACCATGGACACCGGGACTGCGCCCAGTACCTGCGGGAGGTGGCCCAGCCGGTGCCCCTGCTGATGACGCCCCCACCACCACCGTTCCCCCCACCTCCACTGTTGGCCACGAGGCGCTCCCTGGAGGATGGAAGAAGAGGAGGCCCAGGGCCAGGGAACCCCAGCCCCATGTCCCTCAGCCCGGCCTGGCCTGGCCATCCTGACCAGCCTCTTCCCAGGGAGCAGATGACCAGCCCGGCCCCTCCGAGGATCATCACCAGTGCCACGGCTGACCCCGAGGGGACAGAGACGGCGCTGGCGGGGGACACCTCAGATGGCCTGGCCGCACTACAGCTGGATGGGCTGCCCTCAGGCGACATCGACGGGCTGGTGCCCACGCGGGATGAGCGCGGCCAGCCCATCCCAGAGTGGAAGCGGCAGGTGATGGTGCGGAAGCTGCAGGCGCGCCTGGGCGCAGAGAGCTCCGCAGAGGCCCAGGACAATGGTGGGAGCTCAGGCCCCACGGAGCAGGCGGCCTGGAGGTACTCACAGACTCATCAGGCCATCCTGGGGCCCTTTGGGGAGCTGCTGACAGAGGATGACCTGGTCTACCTGGAGAAGCAGATTGCAGACCTGCAGCTTCGGCGCCGCTGTCAGGAGTATGAGAGTGAGCTGGGCCGGTTGGCGGCTGAGCTGCAGGCCCTGCTGCCCGAGCCCCTGGTCAGCATCACGGTCAACAGCCACTTCCTGCCCCGGGCGCCCGGACTGGAGGTTGAGGAGGCCTCAATCCCAGCGGCTGAGCCCGCAGGGTCTGCGGAGGCCTCAGAGGTGGCCCCCGGGGTGCAGCCCCTGCCCTTCTGGTGCAGCCACATCTCCCGCCTGGTACGCAGCCTGTCCCTGCTGCTGAAGGGCGTGCATGGGCTAGTACAGGGGGATGAGAAGCCATCCACCCGGCCCCTGCAGGACACCTGCAGGGAGGCCTCGGCCAGCCCCCCTCGGAGCGAGGCCCAGCGCCAGATCCAGGAGTGGGGGGTGTCTGTGCGGACGCTGCGGGGCAACTTCGAGTCGGCCTCTGGCCCACTCTGTGGCTTCAACCCTGGCCCCTGCGAGCCGGGGGCCCAGCACAGGCAGTGCCTGAGTGGCTGCTGGCCAGCCCTGCCTAAGCCCCGCAGTGGCCTGGCTTCAGGGGAGCCCAGGCCTGGCGACACAGAGGAGGCCAGCGACTCTGGCATCAGCTGCGAGGAGGTGCCATCAGAGGCGGGTGCCGCAGCCGGCCCAGACCTGGCCAGCCTGCGCAAGGAGCGCATCATCATGCTCTTCCTCAGCCACTGGAGGAGATCGGCCTACACGCCGGCCCTCAAGACAGTGGCCTGCAGGACCCTAGGAGCCCGCCACGCGGGGTTGCGGGGCCAGGAGGCCGCCAGGAGCCCTGGGCCACCCTCCCCGCCCAGCGAGGGCCCCCGGCTGGGCCACCTGTGGCAGCAGCGCAGCACCATCACCCACCTGCTGGGCAACTGGAAGGCCATCATGGCTCACGTGCCCGCCCGGCAGCTGCGGCGGCTGAGCCGGCAGCCCCGCGGGGCTTTGTCCCCCGAGCAGTTCCTGCCCCACGTGGACGGGGCTCCGGTGCCCTACAGCAGCCTCTCACTGGATCTCTTCATGCTGGGTTACTTCCAGCTGCTGGAGTGCGACCTGCCGGCGGAGGAGCGGAAGCTGCGCCACCTGCTGTGCTTCGAGGTCTTCGAGCACCTGGGCACCCACGGCTGGGAGGCTGTGCGCGCCTTCCACAAGGCCGTGACCGACGAGGTGGCCGCCGGCCGCCGGGCCTGGACCGACGGCTTCGAGGACATCAAAGCCCGCTTCTTTGGCTCCAGCCAGCGTCCCGCCTGGGATACGGAGCCTGGCCGCAAGTCAGGTCTGACCCTGCTCGGGCCCCTGCCTCACGCCGCCGTCCCCTGCAGCGGCCCTGAGCCCACAGCACAGCGGCTGGGGTCCCGCTCCCAGCAGGGCAGCTTCAACGGTGAGGACATCTGCGGCTACATCAACCGCAGCTTTGCCTTCTGGAAGGAGAAGGAAGCTGAGATGTTCAACTTTGGAGAATGA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3utr\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7968,\n        \"samples\": [\n          \"AACAATTTATTTTAAATGTCTAATTTTTGGTTATTCTTGGCAAGCTGATGGTACTTTTTGCATAATCTTTTGTGGATTCTTGGTTGTACTGTAGTTGCATGCATGATTATAGCTCTTGTTTTTCTCACAGTTTCTTTAAAAATCTTTATTAGTGGCTATAATGACGTGGAAATGTAATCTGTGTTTTCTGGTTTTTCATTTATTTGGCCAAAATGTTATATTAATGGAGTTATTGCTATTTTTGCTGTGATAATGGTATTATGCAAGACCATATTCTCAATTATTTGGATATGCAAACTAAAGTATTAAGAGCTAATGTCATTATATATGTAACTTAAATCTAGACACCATCAAAGCATAAAATAAAAATAAAAAGCGTTGCTGAATCTGGGTCGAAAATGTAGTGCGTTTATCCCACTATTCTCTCTGAAAATGTTCTTTAGAAAGGGTAACAAAGATGCTATCCCTCCATTTTCAGTTCTGGAGAACCTTATTAGTTTTTCAAATATTTACTTTATGATGAAACTTAAGTGGTCACATTGGAAATTATTAATTTCTTAAGTAATTTTTTCTGTAACTGCTTTTGTTGATAATCCTGTTGTGGAGGAAGAGTCTTATAATGCTCTGGGCTTTGCTGTCACTCTTTGGTTTTCTTAATTTAATTCTATTTATTTATGTTTTTTGAGACAGGGTCTCATTCCATTGACCTGGCTGGAATGCAGTGGCACCATCATGGCTCACTGCCGCCTTGACTTCCTGGGTTCAGGTGATTCTCCTGCCTCAGCCTCCTGAGTAGCTGGATCACCAGCACAGGCCACTACGGCCTGGCTAATTCTTTTGTATTTTTTTTGTACAGATGGAATCTTGCCATGTTTCCCAGTCTGGTCTGGAACTCCTTGGCTCAAGCGATCTGCCCGCCTTAGCTAGTTTTTTGTTTTTGTTTTTTGAGACAAAGTCTCACTTTGTTGTCCAGGCTAGAGAGTAGTGGCAGGATCTTGGCTCACTGCAGCCTCGACATCCTGGGCTCAGGCAATCCTCCTGCTTCGGCCTATTAAATAGCTCAAACTACAGGCACCCGCCACGATGCCTAGCTAAATTTTTGTATATGTGGTAGAGATGGAGTTTTGCCATGTGGCCCAGGCTAGTCTCGAACTCCTGAACTCAAGTGATCCACCTGCTTTGGCCTCCCAACGTGCTAGGATTACAGGCATGAGCCATTACGTCTGGCCTAGTTTTCTTTAAATACACCGTGTTTACTAGCTTAAATTTTGTGTTGTTTATTACTAAAGCAGAAAATAATTTAGGGTCTTATCCTGGGTAAAATAGCCTTCCATCAGATGAGTACAAAGCAAGAACTTCATAAGAAATTGAAATGAAGATTCAAACTGTTAAAGAAATGATTTAGTTTCACTTTCCTATTAATTATTGAGTAAATATAAAACATCATTAACACTTTGTGGCCTCTCTCAGATGCCTACAAAGAAGGAATGGGTAGGCATTTATGGTTTATAGTTGCCTCATCATGTAACATATTATATCTCAGCTCTAAAAGAAAGTTCTATAGAAGATTATAGATAGAGATTTTGATAACTGGAATGTAGTATGGATATAGGGCTGGTGTACATATACATTTTGAAATTGCTCTTACAAGATTAAATACTATTATAGACCAGATGATGTAGTAAAATGGAATTTCACTTGCCATTGTGAAATAGGTGAAACAAATTCCAGTTTCCTTAGATTTCTTCCCTCTACTTTATGCAATTATCACTGATTTTATTTTTCGTTGTAACAAGTAGTTATTTGTTGTGTGGATTTCTTAAAATTGACATTTAAACAATAAAATCCTGAAAAGAA\",\n          \"CGGGGGAGGGGTGCCCTAGCATCAGAAGGGTTCATGGCCCTTTCCCCTCCTCCCCCCTCAGCTGGGCCTGGGGAGGAGTCGAAGGGGGCTGCAGAGAGGGTAGAGAAGGGACTTTGCAGGTGAATGGCTGGGGCCCCAAATCCAGGAGATTTTCATCAGAGGTGGGTGGGTGTTCACAATATTTATTTTTTCATTTGGTAATGGGAGGGGGGCCTGGGGGTATTTATTTAGGAGGGAGTGTGGTTTCCTTAGAAGGTATAGTCTCTAGCCCTCTAAGGCTGGGGCTGGTGATCAGCCCCAACAGAGAAAATGAGGAGTTTAGAGTTGCAGCTGGGGAAGGGGTTTGAAGGAAGTTGGAAGTGGGGAGGGGTGGGGGCATCTGGTCTCAGAAATGGACCAGCTGGATGCAGGGCAGGGGACTGAGGGTGCTTGAGTAGGATGTGAGACTTCATGGGCCTGGGTTCTGTTGAGTTTTTTCAGTATCAATTTCTTAAACCAAATTTTAAAAAAAACAAGGTGGGGGGGTGCTCATCTCGTGACCTCTGCCACCCACATCCTTCACAAACTCCATGTTTCAGTGTTTGAGTCCATGTTTATTCTGCAAATAAATGGTAATGTATTGGA\",\n          \"ACCCTGCCCTTCCTCTTTGAATTCTTCCGGGGGAAGGGGTGACTGAACTGGGAGTCCAGGGAGGGAGCTGAGGAGCCCTTACCCTCCCACCACTCCCCTCCCAAGACCCAGCCGCCGCCGTTGAGGGCTGAGTCCTTGCTGTGGGATGTGCCAGTGTCCCCACCAACACCAGGAATTTAGACCTTTTCCCTGCACCACTCTCTTCATCCTGGGGGCTCTGTTACACTAATTTGAATAAACTCTCCCCTTTCTTTGCAACTTCCCAGCAACAATAATGATTTTCTTGCCAGGCCGTCTCTTGCTCCCTAATTCATTTCCCAGGAAGCTGTGATACAGGGTGAAATAAAGTCTTGTCTTAGAAACCAGGACCCTAAACCCCACACTATGTAATAGAAACACATGTGTTTTTATGTCTCAAATAAAACTATTATATCACTTGG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cdna_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2741,\n        \"min\": 303,\n        \"max\": 33681,\n        \"num_unique_values\": 4971,\n        \"samples\": [\n          1627,\n          4864,\n          3777\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"5utr_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 205,\n        \"min\": 1,\n        \"max\": 3561,\n        \"num_unique_values\": 837,\n        \"samples\": [\n          178,\n          1385,\n          131\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cds_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1559,\n        \"min\": 96,\n        \"max\": 21246,\n        \"num_unique_values\": 1631,\n        \"samples\": [\n          2802,\n          5406,\n          2436\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3utr_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2063,\n        \"min\": 4,\n        \"max\": 30931,\n        \"num_unique_values\": 3754,\n        \"samples\": [\n          4207,\n          4175,\n          3244\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_abundance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 318.27360494442064,\n        \"min\": 2e-05,\n        \"max\": 16604.0,\n        \"num_unique_values\": 2536,\n        \"samples\": [\n          156.0,\n          0.978,\n          7.23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_TPM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 268.54215041374493,\n        \"min\": 0.005,\n        \"max\": 15457.415,\n        \"num_unique_values\": 3161,\n        \"samples\": [\n          4.275,\n          3.375,\n          12.795\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_per_transcript\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.372312214464826,\n        \"min\": 4.219409282700422e-06,\n        \"max\": 20.16739736946991,\n        \"num_unique_values\": 7538,\n        \"samples\": [\n          0.5659574468085107,\n          0.2380952380952381,\n          14.37578814627995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3422d627-34c9-47d3-8dc0-1a6257fd758e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>protein_id</th>\n",
              "      <th>mrna_id</th>\n",
              "      <th>gene_id</th>\n",
              "      <th>protein_sequence</th>\n",
              "      <th>protein_length</th>\n",
              "      <th>cdna</th>\n",
              "      <th>5utr</th>\n",
              "      <th>cds</th>\n",
              "      <th>3utr</th>\n",
              "      <th>cdna_length</th>\n",
              "      <th>5utr_length</th>\n",
              "      <th>cds_length</th>\n",
              "      <th>3utr_length</th>\n",
              "      <th>protein_abundance</th>\n",
              "      <th>median_TPM</th>\n",
              "      <th>protein_per_transcript</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENSP00000341562</td>\n",
              "      <td>ENST00000341156</td>\n",
              "      <td>ENSG00000135454</td>\n",
              "      <td>MWLGRRALCALVLLLACASLGLLYASTRDAPGLRLPLAPWAPPQSP...</td>\n",
              "      <td>533</td>\n",
              "      <td>GCATTCCCCGCGCGGAGCCGAAGCAGCCGCAACGAGCCGGGAGCTG...</td>\n",
              "      <td>GCATTCCCCGCGCGGAGCCGAAGCAGCCGCAACGAGCCGGGAGCTG...</td>\n",
              "      <td>ATGTGGCTGGGCCGCCGGGCCCTGTGCGCTCTGGTCCTTCTGCTCG...</td>\n",
              "      <td>TGGCCCGCTGGGGATTTCTGACTGTCAGGCTGGGCCTGCCTCCTTG...</td>\n",
              "      <td>5368</td>\n",
              "      <td>431</td>\n",
              "      <td>1602</td>\n",
              "      <td>3335</td>\n",
              "      <td>0.068</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENSP00000290765</td>\n",
              "      <td>ENST00000290765</td>\n",
              "      <td>ENSG00000133433</td>\n",
              "      <td>MGLELFLDLVSQPSRAVYIFAKKNGIPLELRTVDLVKGQHKSKEFL...</td>\n",
              "      <td>244</td>\n",
              "      <td>AGCTGCTGCCCACACCGCGCTCAGCGCCTTCACTGCCATCCCCGCT...</td>\n",
              "      <td>AGCTGCTGCCCACACCGCGCTCAGCGCCTTCACTGCCATCCCCGCT...</td>\n",
              "      <td>ATGGGCCTAGAGCTGTTTCTTGACCTGGTGTCCCAGCCCAGCCGCG...</td>\n",
              "      <td>AGGGTCTGGGATGGGGGCCAGGAGATTAGCAACAAGGATTCATTCT...</td>\n",
              "      <td>1108</td>\n",
              "      <td>64</td>\n",
              "      <td>735</td>\n",
              "      <td>309</td>\n",
              "      <td>57.000</td>\n",
              "      <td>11.385</td>\n",
              "      <td>5.006588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENSP00000256996</td>\n",
              "      <td>ENST00000256996</td>\n",
              "      <td>ENSG00000134574</td>\n",
              "      <td>MAPKKRPETQKTSEIVLRPRNKRSRSPLELEPEAKKLCAKGSGPSR...</td>\n",
              "      <td>427</td>\n",
              "      <td>GGTTTGAACAAGCCCTGGGCATGTTTGGCGGGAAGTTGGCTTAGCT...</td>\n",
              "      <td>GGTTTGAACAAGCCCTGGGCATGTTTGGCGGGAAGTTGGCTTAGCT...</td>\n",
              "      <td>ATGGCTCCCAAGAAACGCCCAGAAACCCAGAAGACCTCCGAGATTG...</td>\n",
              "      <td>GAGACACTAAAGAAGGTGTGGGCCAGACAAGGCCTTGGAGCCCACA...</td>\n",
              "      <td>1815</td>\n",
              "      <td>163</td>\n",
              "      <td>1284</td>\n",
              "      <td>368</td>\n",
              "      <td>2.510</td>\n",
              "      <td>3.740</td>\n",
              "      <td>0.671123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENSP00000262990</td>\n",
              "      <td>ENST00000262990</td>\n",
              "      <td>ENSG00000109445</td>\n",
              "      <td>MPKKKTGARKKAENRREREKQLRASRSTIDLAKHPCNASMECDKCQ...</td>\n",
              "      <td>320</td>\n",
              "      <td>GCTGTCGTAAAAGGACGTCCGGTCCGTCTCCTAGTGTCCGGAATCG...</td>\n",
              "      <td>GCTGTCGTAAAAGGACGTCCGGTCCGTCTCCTAGTGTCCGGAATCG...</td>\n",
              "      <td>ATGCCTAAAAAAAAGACTGGTGCGAGGAAGAAGGCTGAGAACCGCC...</td>\n",
              "      <td>GGGAGCTGCTCTGGTGGCCGTGTGTGAGAGGAGCAGGAGTGAGTGT...</td>\n",
              "      <td>1891</td>\n",
              "      <td>220</td>\n",
              "      <td>963</td>\n",
              "      <td>708</td>\n",
              "      <td>2.500</td>\n",
              "      <td>13.445</td>\n",
              "      <td>0.185943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENSP00000371811</td>\n",
              "      <td>ENST00000382374</td>\n",
              "      <td>ENSG00000165487</td>\n",
              "      <td>MAAAAGSCARVAAWGGKLRRGLAVSRQAVRSPGPLAAAVAGAALAG...</td>\n",
              "      <td>434</td>\n",
              "      <td>GCCTAGCTGCGCTTCCGCAAAGATGGCGGCGGCTGCGGGTAGCTGC...</td>\n",
              "      <td>GCCTAGCTGCGCTTCCGCAAAG</td>\n",
              "      <td>ATGGCGGCGGCTGCGGGTAGCTGCGCGCGGGTGGCGGCCTGGGGCG...</td>\n",
              "      <td>TAAAAGATATAATAGTATGGCAATTATATTGTTCCAAATGTCAAAA...</td>\n",
              "      <td>1885</td>\n",
              "      <td>22</td>\n",
              "      <td>1305</td>\n",
              "      <td>558</td>\n",
              "      <td>2.500</td>\n",
              "      <td>8.060</td>\n",
              "      <td>0.310174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7982</th>\n",
              "      <td>ENSP00000387111</td>\n",
              "      <td>ENST00000410042</td>\n",
              "      <td>ENSG00000273155</td>\n",
              "      <td>MAGILRLVVQWPPGRLQTVTKGVESLICTDWIRHKFTRSRIPEKVF...</td>\n",
              "      <td>131</td>\n",
              "      <td>GCACTTTTCCAGCTCGAGCCCTCACGAGGCCGTGGGTACGACCGGA...</td>\n",
              "      <td>GCACTTTTCCAGCTCGAGCCCTCACGAGGCCGTGGGTACGACCGGA...</td>\n",
              "      <td>ATGGCTGGGATTTTGCGCTTAGTAGTTCAATGGCCCCCAGGCAGAC...</td>\n",
              "      <td>TGTAATTCTAAATGCATTTTTCTTTTTTCGTTAATGTTCTGAAAAA...</td>\n",
              "      <td>669</td>\n",
              "      <td>207</td>\n",
              "      <td>396</td>\n",
              "      <td>66</td>\n",
              "      <td>1.010</td>\n",
              "      <td>0.155</td>\n",
              "      <td>6.516129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7983</th>\n",
              "      <td>ENSP00000477037</td>\n",
              "      <td>ENST00000553909</td>\n",
              "      <td>ENSG00000259171</td>\n",
              "      <td>MVMGLGVLLLVFVLGLGLTPPTLAQDNSRHL</td>\n",
              "      <td>31</td>\n",
              "      <td>ACACACTCACACAAGGACGCCAACCCCACCTAGATGCAAAGCAGGA...</td>\n",
              "      <td>ACACACTCACACAAGGACGCCAACCCCACCTAGATGCAAAGCAGGA...</td>\n",
              "      <td>ATGGTGATGGGCCTGGGCGTTTTGTTGTTGGTCTTCGTGCTGGGTC...</td>\n",
              "      <td>GATACTGATGGCTCTGCAGAGGACCCATTCATTGCTTCTGCTTTTG...</td>\n",
              "      <td>1498</td>\n",
              "      <td>190</td>\n",
              "      <td>96</td>\n",
              "      <td>1212</td>\n",
              "      <td>0.591</td>\n",
              "      <td>24.155</td>\n",
              "      <td>0.024467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7984</th>\n",
              "      <td>ENSP00000361601</td>\n",
              "      <td>ENST00000372523</td>\n",
              "      <td>ENSG00000168612</td>\n",
              "      <td>MLERLKAPWSAALQRKYFDLGIWTAPISPMALTMLNGLLIKDSSPP...</td>\n",
              "      <td>485</td>\n",
              "      <td>AAATAGGGAGAAATGGCGACGGAGCCTGGCTGTGGGCCCATCTTTG...</td>\n",
              "      <td>AAATAGGGAGAAATGGCGACGGAGCCTGGCTGTGGGCCCATCTTTG...</td>\n",
              "      <td>ATGCTTGAGAGACTCAAAGCCCCGTGGTCAGCTGCCCTGCAAAGAA...</td>\n",
              "      <td>TTATTCTCGATGCCCAGAGATGCTCATGCACCTGTGCACACTCACA...</td>\n",
              "      <td>2769</td>\n",
              "      <td>95</td>\n",
              "      <td>1458</td>\n",
              "      <td>1216</td>\n",
              "      <td>0.030</td>\n",
              "      <td>2.750</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7985</th>\n",
              "      <td>ENSP00000437563</td>\n",
              "      <td>ENST00000539033</td>\n",
              "      <td>ENSG00000255641</td>\n",
              "      <td>MNKQRGTFSEVSLAQDPKRQQRKPKGNKSSISGTEQEIFQVELNLQ...</td>\n",
              "      <td>240</td>\n",
              "      <td>CACACAGCTGCAGAGATGAATAAACAAAGAGGAACCTTCTCAGAAG...</td>\n",
              "      <td>CACACAGCTGCAGAG</td>\n",
              "      <td>ATGAATAAACAAAGAGGAACCTTCTCAGAAGTGAGTCTGGCCCAGG...</td>\n",
              "      <td>GCTCAAGAAATCAACACATCTTGGCCTCCCAAGTTGCTGGGATTAC...</td>\n",
              "      <td>998</td>\n",
              "      <td>15</td>\n",
              "      <td>723</td>\n",
              "      <td>260</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.110</td>\n",
              "      <td>0.927273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7986</th>\n",
              "      <td>ENSP00000483386</td>\n",
              "      <td>ENST00000619918</td>\n",
              "      <td>ENSG00000275793</td>\n",
              "      <td>MAKDSPSPLGASPKKPGCSSPAAAVLENQRRELEKLRAELEAERAG...</td>\n",
              "      <td>1639</td>\n",
              "      <td>CCAGCCACCTGACCCAAATACACCACCTGAACCCACGACCAGGTAT...</td>\n",
              "      <td>CCAGCCACCTGACCCAAATACACCACCTGAACCCACGACCAGGTAT...</td>\n",
              "      <td>ATGGCCAAGGACTCGCCCAGCCCCTTGGGCGCGTCGCCCAAGAAGC...</td>\n",
              "      <td>GCAAGCATCCTTGCCCAGGTAGTGGCCTCTGGCTGCTCACACCCTG...</td>\n",
              "      <td>6105</td>\n",
              "      <td>485</td>\n",
              "      <td>4920</td>\n",
              "      <td>700</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7987 rows × 16 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3422d627-34c9-47d3-8dc0-1a6257fd758e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3422d627-34c9-47d3-8dc0-1a6257fd758e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3422d627-34c9-47d3-8dc0-1a6257fd758e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6c70befe-baff-40aa-8c0b-3a0e892f964c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c70befe-baff-40aa-8c0b-3a0e892f964c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6c70befe-baff-40aa-8c0b-3a0e892f964c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           protein_id          mrna_id          gene_id  \\\n",
              "0     ENSP00000341562  ENST00000341156  ENSG00000135454   \n",
              "1     ENSP00000290765  ENST00000290765  ENSG00000133433   \n",
              "2     ENSP00000256996  ENST00000256996  ENSG00000134574   \n",
              "3     ENSP00000262990  ENST00000262990  ENSG00000109445   \n",
              "4     ENSP00000371811  ENST00000382374  ENSG00000165487   \n",
              "...               ...              ...              ...   \n",
              "7982  ENSP00000387111  ENST00000410042  ENSG00000273155   \n",
              "7983  ENSP00000477037  ENST00000553909  ENSG00000259171   \n",
              "7984  ENSP00000361601  ENST00000372523  ENSG00000168612   \n",
              "7985  ENSP00000437563  ENST00000539033  ENSG00000255641   \n",
              "7986  ENSP00000483386  ENST00000619918  ENSG00000275793   \n",
              "\n",
              "                                       protein_sequence  protein_length  \\\n",
              "0     MWLGRRALCALVLLLACASLGLLYASTRDAPGLRLPLAPWAPPQSP...             533   \n",
              "1     MGLELFLDLVSQPSRAVYIFAKKNGIPLELRTVDLVKGQHKSKEFL...             244   \n",
              "2     MAPKKRPETQKTSEIVLRPRNKRSRSPLELEPEAKKLCAKGSGPSR...             427   \n",
              "3     MPKKKTGARKKAENRREREKQLRASRSTIDLAKHPCNASMECDKCQ...             320   \n",
              "4     MAAAAGSCARVAAWGGKLRRGLAVSRQAVRSPGPLAAAVAGAALAG...             434   \n",
              "...                                                 ...             ...   \n",
              "7982  MAGILRLVVQWPPGRLQTVTKGVESLICTDWIRHKFTRSRIPEKVF...             131   \n",
              "7983                    MVMGLGVLLLVFVLGLGLTPPTLAQDNSRHL              31   \n",
              "7984  MLERLKAPWSAALQRKYFDLGIWTAPISPMALTMLNGLLIKDSSPP...             485   \n",
              "7985  MNKQRGTFSEVSLAQDPKRQQRKPKGNKSSISGTEQEIFQVELNLQ...             240   \n",
              "7986  MAKDSPSPLGASPKKPGCSSPAAAVLENQRRELEKLRAELEAERAG...            1639   \n",
              "\n",
              "                                                   cdna  \\\n",
              "0     GCATTCCCCGCGCGGAGCCGAAGCAGCCGCAACGAGCCGGGAGCTG...   \n",
              "1     AGCTGCTGCCCACACCGCGCTCAGCGCCTTCACTGCCATCCCCGCT...   \n",
              "2     GGTTTGAACAAGCCCTGGGCATGTTTGGCGGGAAGTTGGCTTAGCT...   \n",
              "3     GCTGTCGTAAAAGGACGTCCGGTCCGTCTCCTAGTGTCCGGAATCG...   \n",
              "4     GCCTAGCTGCGCTTCCGCAAAGATGGCGGCGGCTGCGGGTAGCTGC...   \n",
              "...                                                 ...   \n",
              "7982  GCACTTTTCCAGCTCGAGCCCTCACGAGGCCGTGGGTACGACCGGA...   \n",
              "7983  ACACACTCACACAAGGACGCCAACCCCACCTAGATGCAAAGCAGGA...   \n",
              "7984  AAATAGGGAGAAATGGCGACGGAGCCTGGCTGTGGGCCCATCTTTG...   \n",
              "7985  CACACAGCTGCAGAGATGAATAAACAAAGAGGAACCTTCTCAGAAG...   \n",
              "7986  CCAGCCACCTGACCCAAATACACCACCTGAACCCACGACCAGGTAT...   \n",
              "\n",
              "                                                   5utr  \\\n",
              "0     GCATTCCCCGCGCGGAGCCGAAGCAGCCGCAACGAGCCGGGAGCTG...   \n",
              "1     AGCTGCTGCCCACACCGCGCTCAGCGCCTTCACTGCCATCCCCGCT...   \n",
              "2     GGTTTGAACAAGCCCTGGGCATGTTTGGCGGGAAGTTGGCTTAGCT...   \n",
              "3     GCTGTCGTAAAAGGACGTCCGGTCCGTCTCCTAGTGTCCGGAATCG...   \n",
              "4                                GCCTAGCTGCGCTTCCGCAAAG   \n",
              "...                                                 ...   \n",
              "7982  GCACTTTTCCAGCTCGAGCCCTCACGAGGCCGTGGGTACGACCGGA...   \n",
              "7983  ACACACTCACACAAGGACGCCAACCCCACCTAGATGCAAAGCAGGA...   \n",
              "7984  AAATAGGGAGAAATGGCGACGGAGCCTGGCTGTGGGCCCATCTTTG...   \n",
              "7985                                    CACACAGCTGCAGAG   \n",
              "7986  CCAGCCACCTGACCCAAATACACCACCTGAACCCACGACCAGGTAT...   \n",
              "\n",
              "                                                    cds  \\\n",
              "0     ATGTGGCTGGGCCGCCGGGCCCTGTGCGCTCTGGTCCTTCTGCTCG...   \n",
              "1     ATGGGCCTAGAGCTGTTTCTTGACCTGGTGTCCCAGCCCAGCCGCG...   \n",
              "2     ATGGCTCCCAAGAAACGCCCAGAAACCCAGAAGACCTCCGAGATTG...   \n",
              "3     ATGCCTAAAAAAAAGACTGGTGCGAGGAAGAAGGCTGAGAACCGCC...   \n",
              "4     ATGGCGGCGGCTGCGGGTAGCTGCGCGCGGGTGGCGGCCTGGGGCG...   \n",
              "...                                                 ...   \n",
              "7982  ATGGCTGGGATTTTGCGCTTAGTAGTTCAATGGCCCCCAGGCAGAC...   \n",
              "7983  ATGGTGATGGGCCTGGGCGTTTTGTTGTTGGTCTTCGTGCTGGGTC...   \n",
              "7984  ATGCTTGAGAGACTCAAAGCCCCGTGGTCAGCTGCCCTGCAAAGAA...   \n",
              "7985  ATGAATAAACAAAGAGGAACCTTCTCAGAAGTGAGTCTGGCCCAGG...   \n",
              "7986  ATGGCCAAGGACTCGCCCAGCCCCTTGGGCGCGTCGCCCAAGAAGC...   \n",
              "\n",
              "                                                   3utr  cdna_length  \\\n",
              "0     TGGCCCGCTGGGGATTTCTGACTGTCAGGCTGGGCCTGCCTCCTTG...         5368   \n",
              "1     AGGGTCTGGGATGGGGGCCAGGAGATTAGCAACAAGGATTCATTCT...         1108   \n",
              "2     GAGACACTAAAGAAGGTGTGGGCCAGACAAGGCCTTGGAGCCCACA...         1815   \n",
              "3     GGGAGCTGCTCTGGTGGCCGTGTGTGAGAGGAGCAGGAGTGAGTGT...         1891   \n",
              "4     TAAAAGATATAATAGTATGGCAATTATATTGTTCCAAATGTCAAAA...         1885   \n",
              "...                                                 ...          ...   \n",
              "7982  TGTAATTCTAAATGCATTTTTCTTTTTTCGTTAATGTTCTGAAAAA...          669   \n",
              "7983  GATACTGATGGCTCTGCAGAGGACCCATTCATTGCTTCTGCTTTTG...         1498   \n",
              "7984  TTATTCTCGATGCCCAGAGATGCTCATGCACCTGTGCACACTCACA...         2769   \n",
              "7985  GCTCAAGAAATCAACACATCTTGGCCTCCCAAGTTGCTGGGATTAC...          998   \n",
              "7986  GCAAGCATCCTTGCCCAGGTAGTGGCCTCTGGCTGCTCACACCCTG...         6105   \n",
              "\n",
              "      5utr_length  cds_length  3utr_length  protein_abundance  median_TPM  \\\n",
              "0             431        1602         3335              0.068       0.100   \n",
              "1              64         735          309             57.000      11.385   \n",
              "2             163        1284          368              2.510       3.740   \n",
              "3             220         963          708              2.500      13.445   \n",
              "4              22        1305          558              2.500       8.060   \n",
              "...           ...         ...          ...                ...         ...   \n",
              "7982          207         396           66              1.010       0.155   \n",
              "7983          190          96         1212              0.591      24.155   \n",
              "7984           95        1458         1216              0.030       2.750   \n",
              "7985           15         723          260              0.102       0.110   \n",
              "7986          485        4920          700              0.010       0.010   \n",
              "\n",
              "      protein_per_transcript  \n",
              "0                   0.680000  \n",
              "1                   5.006588  \n",
              "2                   0.671123  \n",
              "3                   0.185943  \n",
              "4                   0.310174  \n",
              "...                      ...  \n",
              "7982                6.516129  \n",
              "7983                0.024467  \n",
              "7984                0.010909  \n",
              "7985                0.927273  \n",
              "7986                1.000000  \n",
              "\n",
              "[7987 rows x 16 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"cleaned_liver_data_cdna.csv\")\n",
        "print(df[\"protein_length\"].max())\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q6qHZA32COFi"
      },
      "outputs": [],
      "source": [
        "sequences = df[\"protein_sequence\"].to_list()\n",
        "sequence_ids = df[\"protein_id\"].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaeEUcljSY_o",
        "outputId": "bad86ff6-7d79-4058-a48a-a79c3c223ddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model attributes:\n",
            "- esm\n",
            "- esm_s_mlp\n",
            "- embedding\n",
            "- trunk\n",
            "- distogram_head\n",
            "- ptm_head\n",
            "- lm_head\n",
            "- lddt_head\n",
            "\n",
            "Trunk module attributes:\n",
            "- pairwise_positional_embedding\n",
            "- blocks\n",
            "- recycle_s_norm\n",
            "- recycle_z_norm\n",
            "- recycle_disto\n",
            "- structure_module\n",
            "- trunk2sm_s\n",
            "- trunk2sm_z\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Print model's top-level attributes\n",
        "print(\"Model attributes:\")\n",
        "for name, module in model.named_children():\n",
        "    print(f\"- {name}\")\n",
        "\n",
        "# Specifically look at the trunk module\n",
        "print(\"\\nTrunk module attributes:\")\n",
        "for name, module in model.trunk.named_children():\n",
        "    print(f\"- {name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFPp7TqjFtxK",
        "outputId": "1b5a7a0b-7a48-49c9-9c68-0250823a5766"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[-1.5312e+01, -1.1654e+01,  2.0418e+01,  ...,  7.2015e+01,\n",
              "            6.5953e+01,  9.4722e+00],\n",
              "          [ 2.0443e+01, -1.7881e+01,  9.9735e+00,  ...,  5.0363e+01,\n",
              "            2.2189e+01,  7.3537e+00],\n",
              "          [-1.4686e+01, -8.0592e+00, -1.6122e+00,  ...,  5.5027e+01,\n",
              "            2.4880e+01, -1.3444e+01],\n",
              "          ...,\n",
              "          [ 7.1311e+00, -5.6107e+00, -1.3823e+01,  ..., -1.4397e+01,\n",
              "            1.6523e+01,  2.6203e+00],\n",
              "          [ 6.6875e+00, -6.1878e+00, -1.0535e+01,  ..., -2.3282e+01,\n",
              "            8.6818e+00, -2.3309e+00],\n",
              "          [ 5.0486e+00, -7.3074e+00, -7.5575e+00,  ..., -6.2829e+00,\n",
              "            8.7185e+00, -2.8480e+00]],\n",
              "\n",
              "         [[ 1.2287e+01, -1.7487e+01, -2.2553e+01,  ...,  6.1522e+01,\n",
              "            2.7221e+01,  4.5899e+00],\n",
              "          [-1.2862e+01, -4.9824e+00,  4.8187e+00,  ...,  9.2095e+01,\n",
              "            7.0474e+01,  3.1940e+00],\n",
              "          [ 3.7239e+01, -3.9221e+01, -1.2296e+01,  ...,  6.0434e+01,\n",
              "            3.6214e+01, -7.5250e-01],\n",
              "          ...,\n",
              "          [-7.3794e-01,  3.4400e+00, -2.4215e+00,  ..., -1.6781e+01,\n",
              "            4.3839e+00,  8.1832e-01],\n",
              "          [ 1.3204e-01,  5.1454e+00, -2.3685e+00,  ..., -2.1067e+01,\n",
              "            5.8194e+00,  5.0552e+00],\n",
              "          [ 1.2290e+00,  2.3078e+00, -4.4221e+00,  ..., -1.0396e+01,\n",
              "            5.0421e+00, -1.2526e+00]],\n",
              "\n",
              "         [[-1.0076e+01,  1.0172e+01, -8.4622e-01,  ...,  7.9516e+01,\n",
              "           -1.6059e+01, -3.8952e+00],\n",
              "          [ 9.7141e+00, -4.9904e+00, -4.6802e+00,  ...,  5.0925e+01,\n",
              "           -2.2278e+00,  8.0185e-01],\n",
              "          [-1.3716e+01, -5.0887e+00,  4.8797e+00,  ...,  9.4964e+01,\n",
              "            7.4955e+01,  6.7095e+00],\n",
              "          ...,\n",
              "          [-2.7362e+00,  7.9213e-01, -8.8271e+00,  ..., -2.7760e+01,\n",
              "            8.2705e+00,  1.5621e+00],\n",
              "          [ 3.3829e+00, -4.2340e-01, -6.2535e+00,  ..., -3.0705e+01,\n",
              "            5.8405e+00,  3.6479e+00],\n",
              "          [ 3.8943e+00, -3.9863e+00, -7.2738e+00,  ..., -2.3061e+01,\n",
              "            2.9619e+00,  3.2377e+00]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 4.4079e+00, -1.3352e+00, -2.3931e-01,  ..., -8.7310e+00,\n",
              "           -3.4962e+00,  7.2091e+00],\n",
              "          [ 2.3514e+00, -2.3920e+00,  5.3867e+00,  ..., -1.8686e+01,\n",
              "           -4.9477e+00,  8.6477e+00],\n",
              "          [-5.8342e-02, -3.8729e+00,  2.1534e+00,  ..., -1.8598e+01,\n",
              "           -4.6513e+00,  4.9593e+00],\n",
              "          ...,\n",
              "          [-5.0636e+00, -1.4672e+01,  2.2090e+01,  ...,  1.7357e+02,\n",
              "            7.6673e+01,  3.6034e+01],\n",
              "          [ 2.9938e+00, -1.4491e+01,  3.2362e+00,  ...,  6.3077e+01,\n",
              "            4.4190e+01,  1.0178e+01],\n",
              "          [-1.2898e+01, -1.1774e+01, -2.5977e+01,  ...,  6.5105e+01,\n",
              "           -2.4562e+01, -1.2700e+01]],\n",
              "\n",
              "         [[ 1.1167e+00,  2.8692e+00, -3.5298e+00,  ..., -1.0567e+01,\n",
              "           -7.9119e+00,  5.7157e+00],\n",
              "          [-7.5241e-01,  3.0053e+00,  3.1576e+00,  ..., -1.7143e+01,\n",
              "           -5.5945e+00,  4.3928e+00],\n",
              "          [-2.1975e+00,  9.0243e-01, -4.7173e+00,  ..., -2.0202e+01,\n",
              "           -4.1969e+00,  8.8075e+00],\n",
              "          ...,\n",
              "          [ 3.5168e+01,  3.5129e+00, -4.2751e+01,  ...,  1.3295e+02,\n",
              "            3.0095e+01,  2.2178e+00],\n",
              "          [-9.3842e+00, -8.0408e+00,  1.5225e+01,  ...,  1.5527e+02,\n",
              "            9.4101e+01,  1.9837e+01],\n",
              "          [ 2.4074e+00,  9.5164e+00,  1.8470e+01,  ...,  4.4767e+01,\n",
              "            1.3503e+01,  2.5135e+01]],\n",
              "\n",
              "         [[-2.9996e+00, -2.2235e+00, -8.0509e+00,  ..., -6.8785e+00,\n",
              "           -2.3647e+00, -1.9884e+00],\n",
              "          [-2.1274e+00, -2.0911e+00, -1.6722e+00,  ..., -7.9986e+00,\n",
              "           -3.3624e+00, -1.4426e-01],\n",
              "          [-3.7435e+00, -2.2590e+00, -6.6262e+00,  ..., -1.2381e+01,\n",
              "            2.7851e+00,  1.2752e+00],\n",
              "          ...,\n",
              "          [-5.9267e+00, -8.4194e+00, -5.9388e+00,  ...,  5.8812e+01,\n",
              "            2.3075e+00, -6.2402e+00],\n",
              "          [ 2.6703e+01, -1.0911e+00, -3.3920e+01,  ...,  9.0755e+01,\n",
              "            5.6976e-02, -7.4424e+00],\n",
              "          [ 1.4070e+01, -1.1399e+01,  2.7933e+01,  ...,  1.1911e+02,\n",
              "            6.1201e+01,  2.9914e+01]]]], device='cuda:0')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_protein = \"MGAGASAEEKHSRELEKKLKEDAEKDARTVKLLLLGAGESGKSTIVKQMKIIHQDGYSLEECLEFIAIIYGNTLQSILAIVRAMTTLNIQYGDSARQDDARKLMHMADTIEEGTMPKEMSDIIQRLWKDSGIQACFERASEYQLNDSAGYYLSDLERLVTPGYVPTEQDVLRSRVKTTGIIETQFSFKDLNFRMFDVGGQRSERKKWIHCFEGVTCIIFIAALSAYDMVLVEDDEVNRMHESLHLFNSICNHRYFATTSIVLFLNKKDVFFEKIKKAHLSICFPDYDGPNTYEDAGNYIKVQFLELNMRRDVKEIYSHMTCATDTQNVKFVFDAVTDIIIKENLKDCGLF\"\n",
        "\n",
        "tokenized_input = tokenizer([test_protein], return_tensors=\"pt\", add_special_tokens=False)['input_ids']\n",
        "tokenized_input = tokenized_input.cuda()\n",
        "\n",
        "import torch\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(tokenized_input)\n",
        "\n",
        "output['s_z']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xww08U1tHycR",
        "outputId": "236d992e-2483-4666-ab55-b55ae7d64659"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   1%|          | 15/1997 [00:48<1:45:15,  3.19s/it]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "Processing batches:   3%|▎         | 51/1997 [02:38<1:16:03,  2.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing batch: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  16%|█▌        | 311/1997 [16:11<1:07:06,  2.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing batch: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  20%|██        | 401/1997 [20:52<1:23:54,  3.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing batch: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  39%|███▉      | 784/1997 [40:53<1:02:40,  3.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing batch: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  44%|████▍     | 881/1997 [45:55<57:42,  3.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing batch: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  48%|████▊     | 951/1997 [49:34<55:37,  3.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing batch: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  49%|████▉     | 978/1997 [50:56<53:22,  3.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing batch: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  49%|████▉     | 987/1997 [51:22<51:39,  3.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing batch: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 1045/1997 [54:24<49:26,  3.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing batch: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  53%|█████▎    | 1060/1997 [55:06<36:19,  2.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing batch: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  55%|█████▌    | 1108/1997 [57:36<45:40,  3.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing batch: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  62%|██████▏   | 1235/1997 [1:04:12<39:14,  3.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing batch: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  74%|███████▍  | 1487/1997 [1:17:13<19:29,  2.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing batch: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  81%|████████  | 1612/1997 [1:23:44<15:16,  2.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing batch: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  94%|█████████▎| 1868/1997 [1:37:14<05:03,  2.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing batch: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 1997/1997 [1:44:05<00:00,  3.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully processed 7927 sequences\n",
            "Skipped 60 sequences\n",
            "DataFrame shape: (7927, 385)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import os\n",
        "\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "\n",
        "def batch_sequences(sequences, sequence_ids, batch_size=8):\n",
        "    for i in range(0, len(sequences), batch_size):\n",
        "        yield sequences[i : i + batch_size], sequence_ids[i : i + batch_size]\n",
        "\n",
        "\n",
        "embeddings_list = []\n",
        "processed_ids = []\n",
        "skipped_sequences = []\n",
        "\n",
        "batch_size = 4\n",
        "total_batches = (len(sequences) + batch_size - 1) // batch_size\n",
        "\n",
        "clear_gpu_memory()\n",
        "\n",
        "for batch_sequences, batch_ids in tqdm(\n",
        "    batch_sequences(sequences, sequence_ids, batch_size),\n",
        "    total=total_batches,\n",
        "    desc=\"Processing batches\",\n",
        "):\n",
        "    try:\n",
        "        clear_gpu_memory()\n",
        "\n",
        "        tokenized_input = tokenizer(\n",
        "            batch_sequences,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=1024,\n",
        "            add_special_tokens=False,\n",
        "        )[\"input_ids\"]\n",
        "\n",
        "        # Get attention mask for proper mean pooling\n",
        "        attention_mask = (tokenized_input != tokenizer.pad_token_id).float()\n",
        "\n",
        "        tokenized_input = tokenized_input.cuda()\n",
        "        attention_mask = attention_mask.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # ESM-2 processing\n",
        "            esm_output = model.esm(tokenized_input)\n",
        "            last_hidden_state = esm_output.last_hidden_state.clone()\n",
        "            del esm_output\n",
        "            clear_gpu_memory()\n",
        "\n",
        "            # ESM-S projection layer\n",
        "            esm_s = model.esm_s_mlp(last_hidden_state)\n",
        "            del last_hidden_state\n",
        "            clear_gpu_memory()\n",
        "\n",
        "            # Project to structure module dimension (1024 -> 384)\n",
        "            structure_embeddings = model.trunk.trunk2sm_s(\n",
        "                esm_s\n",
        "            )  # [batch_size, seq_len, 384]\n",
        "            del esm_s\n",
        "            clear_gpu_memory()\n",
        "\n",
        "            # Apply mean pooling\n",
        "            masked_embeddings = structure_embeddings * attention_mask.unsqueeze(-1)\n",
        "            del structure_embeddings\n",
        "            clear_gpu_memory()\n",
        "\n",
        "            # Sum and divide by the number of actual tokens\n",
        "            sum_embeddings = masked_embeddings.sum(dim=1)  # [batch_size, 384]\n",
        "            del masked_embeddings\n",
        "            clear_gpu_memory()\n",
        "\n",
        "            seq_lengths = attention_mask.sum(dim=1, keepdim=True)  # [batch_size, 1]\n",
        "            del attention_mask\n",
        "            clear_gpu_memory()\n",
        "\n",
        "            mean_pooled_embeddings = sum_embeddings / seq_lengths\n",
        "            del sum_embeddings, seq_lengths\n",
        "            clear_gpu_memory()\n",
        "\n",
        "            # Convert to numpy and store\n",
        "            structure_embeddings_np = mean_pooled_embeddings.cpu().numpy()\n",
        "            del mean_pooled_embeddings\n",
        "            clear_gpu_memory()\n",
        "\n",
        "            # Store embeddings and IDs\n",
        "            embeddings_list.append(structure_embeddings_np)\n",
        "            processed_ids.extend(batch_ids)\n",
        "\n",
        "            del structure_embeddings_np\n",
        "            clear_gpu_memory()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing batch: {str(e)}\")\n",
        "        skipped_sequences.extend(batch_ids)\n",
        "        clear_gpu_memory()\n",
        "        continue\n",
        "\n",
        "    if len(embeddings_list) % 100 == 0:\n",
        "        # Save temporary results\n",
        "        temp_embeddings = np.concatenate(embeddings_list, axis=0)\n",
        "        temp_df = pd.DataFrame(\n",
        "            temp_embeddings, columns=[f\"esm_struct_{i}\" for i in range(384)]\n",
        "        )\n",
        "        temp_df.insert(0, \"id\", processed_ids)\n",
        "        temp_df.to_csv(\n",
        "            f\"structure_embeddings_temp_{len(processed_ids)}.csv\", index=False\n",
        "        )\n",
        "        del temp_df, temp_embeddings\n",
        "        clear_gpu_memory()\n",
        "\n",
        "try:\n",
        "    all_embeddings = np.concatenate(embeddings_list, axis=0)\n",
        "\n",
        "    embedding_columns = [f\"esm_struct_{i}\" for i in range(384)]\n",
        "\n",
        "    df_structure = pd.DataFrame(all_embeddings, columns=embedding_columns)\n",
        "    df_structure.insert(0, \"id\", processed_ids)\n",
        "\n",
        "    print(f\"Successfully processed {len(processed_ids)} sequences\")\n",
        "    print(f\"Skipped {len(skipped_sequences)} sequences\")\n",
        "    print(f\"DataFrame shape: {df_structure.shape}\")\n",
        "\n",
        "    df_structure.to_csv(\"prot_structure_embeddings.csv\", index=False)\n",
        "\n",
        "    for file in os.listdir():\n",
        "        if file.startswith(\"structure_embeddings_temp_\"):\n",
        "            os.remove(file)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error in final processing: {str(e)}\")\n",
        "    print(\"Attempting to save partial results...\")\n",
        "    for i, (emb_batch, ids_batch) in enumerate(\n",
        "        zip(\n",
        "            embeddings_list,\n",
        "            [\n",
        "                processed_ids[i : i + batch_size]\n",
        "                for i in range(0, len(processed_ids), batch_size)\n",
        "            ],\n",
        "        )\n",
        "    ):\n",
        "        temp_df = pd.DataFrame(\n",
        "            emb_batch, columns=[f\"esm_struct_{i}\" for i in range(384)]\n",
        "        )\n",
        "        temp_df.insert(0, \"id\", ids_batch)\n",
        "        temp_df.to_csv(f\"structure_embeddings_partial_{i}.csv\", index=False)\n",
        "\n",
        "finally:\n",
        "    # Clear all remaining variables\n",
        "    del embeddings_list, processed_ids, skipped_sequences\n",
        "    clear_gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxGx9yCTC7lz",
        "outputId": "a59e5f6b-48bd-4ebb-d78c-0a6471623992"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EsmTokenizer(name_or_path='facebook/esmfold_v1', vocab_size=26, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': 'A', 'cls_token': '<cls>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
              "\t0: AddedToken(\"A\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t22: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t23: AddedToken(\"<cls>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t25: AddedToken(\"<eos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t26: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ESMFold and ESM-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lin, Z., Akin, H., Rao, R., Hie, B., Zhu, Z., Lu, W., Smetanin, N., Verkuil, R., Kabeli, O., Shmueli, Y., Costa, A. D. S., Fazel-Zarandi, M., Sercu, T., Candido, S., & Rives, A. (2023). Evolutionary-scale prediction of atomic-level protein structure with a language model. Science, 379(6637), 1123–1130. https://doi.org/10.1126/science.ade2574\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
